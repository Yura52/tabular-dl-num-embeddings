{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train3___5000f35982ba4380b4c8b08f254dc1f1.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8700087950747581,
                "recall": 0.9705651491365777,
                "f1-score": 0.9175401168722753,
                "support": 5096
            },
            "1": {
                "precision": 0.7902097902097902,
                "recall": 0.43328220858895705,
                "f1-score": 0.559683011391778,
                "support": 1304
            },
            "accuracy": 0.86109375,
            "macro avg": {
                "precision": 0.8301092926422742,
                "recall": 0.7019236788627674,
                "f1-score": 0.7386115641320267,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.853749747833521,
                "recall": 0.86109375,
                "f1-score": 0.844626731630624,
                "support": 6400
            },
            "roc_auc": 0.8704047924030395,
            "score": 0.86109375
        },
        "val": {
            "0": {
                "precision": 0.8731604765241766,
                "recall": 0.978021978021978,
                "f1-score": 0.9226212513883747,
                "support": 1274
            },
            "1": {
                "precision": 0.838150289017341,
                "recall": 0.4447852760736196,
                "f1-score": 0.5811623246492986,
                "support": 326
            },
            "accuracy": 0.869375,
            "macro avg": {
                "precision": 0.8556553827707588,
                "recall": 0.7114036270477988,
                "f1-score": 0.7518917880188367,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.866027150819659,
                "recall": 0.869375,
                "f1-score": 0.853048995065288,
                "support": 1600
            },
            "roc_auc": 0.8659648852462174,
            "score": 0.869375
        },
        "test": {
            "0": {
                "precision": 0.8633333333333333,
                "recall": 0.975517890772128,
                "f1-score": 0.9160035366931918,
                "support": 1593
            },
            "1": {
                "precision": 0.805,
                "recall": 0.3955773955773956,
                "f1-score": 0.5304777594728171,
                "support": 407
            },
            "accuracy": 0.8575,
            "macro avg": {
                "precision": 0.8341666666666667,
                "recall": 0.6855476431747618,
                "f1-score": 0.7232406480830045,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8514625,
                "recall": 0.8575,
                "f1-score": 0.8375490410288455,
                "support": 2000
            },
            "roc_auc": 0.857680484799129,
            "score": 0.8575
        }
    }
}
