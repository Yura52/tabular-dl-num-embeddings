{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train3___c2d0df569bd6462786fe68f2c64a4228.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7484549858025722,
                "recall": 0.7573862483942938,
                "f1-score": 0.7528941310885965,
                "support": 29582
            },
            "1": {
                "precision": 0.7812957094100439,
                "recall": 0.7729807953209322,
                "f1-score": 0.77711601121467,
                "support": 33169
            },
            "accuracy": 0.7656292330002709,
            "macro avg": {
                "precision": 0.764875347606308,
                "recall": 0.7651835218576131,
                "f1-score": 0.7650050711516332,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7658139754814017,
                "recall": 0.7656292330002709,
                "f1-score": 0.7656973619837493,
                "support": 62751
            },
            "roc_auc": 0.8524070661464938,
            "score": 0.7656292330002709
        },
        "val": {
            "0": {
                "precision": 0.727448275862069,
                "recall": 0.7130881557598702,
                "f1-score": 0.720196640721016,
                "support": 7396
            },
            "1": {
                "precision": 0.7485186063048116,
                "recall": 0.7616980221900627,
                "f1-score": 0.7550508069336521,
                "support": 8292
            },
            "accuracy": 0.7387812340642529,
            "macro avg": {
                "precision": 0.7379834410834403,
                "recall": 0.7373930889749665,
                "f1-score": 0.737623723827334,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7385851435336155,
                "recall": 0.7387812340642529,
                "f1-score": 0.7386190493285618,
                "support": 15688
            },
            "roc_auc": 0.818710251196394,
            "score": 0.7387812340642529
        },
        "test": {
            "0": {
                "precision": 0.7160785154993028,
                "recall": 0.722120064899946,
                "f1-score": 0.7190866006031883,
                "support": 9245
            },
            "1": {
                "precision": 0.7502673276951493,
                "recall": 0.7446213217559093,
                "f1-score": 0.747433662599264,
                "support": 10365
            },
            "accuracy": 0.7340132585415604,
            "macro avg": {
                "precision": 0.733172921597226,
                "recall": 0.7333706933279276,
                "f1-score": 0.7332601316012262,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7341492466777805,
                "recall": 0.7340132585415604,
                "f1-score": 0.734069634646499,
                "support": 19610
            },
            "roc_auc": 0.8131783728417885,
            "score": 0.7340132585415604
        }
    }
}
