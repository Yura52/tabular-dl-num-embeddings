{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train3___b44637b0181b4d1bbcbc3499ecfdf5b7.py",
    "data": "data/adult",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9044103547459252,
                "recall": 0.9540328697850822,
                "f1-score": 0.9285591239079611,
                "support": 19775
            },
            "1": {
                "precision": 0.8247879722436392,
                "recall": 0.6821297624740953,
                "f1-score": 0.7467062210976354,
                "support": 6273
            },
            "accuracy": 0.8885519041769042,
            "macro avg": {
                "precision": 0.8645991634947823,
                "recall": 0.8180813161295888,
                "f1-score": 0.8376326725027983,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8852353238246705,
                "recall": 0.8885519041769042,
                "f1-score": 0.8847644656106189,
                "support": 26048
            },
            "roc_auc": 0.9447079097845339,
            "score": 0.8885519041769042
        },
        "val": {
            "0": {
                "precision": 0.8918453292496171,
                "recall": 0.9421638018200202,
                "f1-score": 0.9163142885239454,
                "support": 4945
            },
            "1": {
                "precision": 0.7781225756400311,
                "recall": 0.6396683673469388,
                "f1-score": 0.7021351067553376,
                "support": 1568
            },
            "accuracy": 0.8693382465837556,
            "macro avg": {
                "precision": 0.8349839524448242,
                "recall": 0.7909160845834795,
                "f1-score": 0.8092246976396416,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.86446665925732,
                "recall": 0.8693382465837556,
                "f1-score": 0.8647508067163026,
                "support": 6513
            },
            "roc_auc": 0.9287957068570604,
            "score": 0.8693382465837556
        },
        "test": {
            "0": {
                "precision": 0.8967919761120894,
                "recall": 0.9419380780056292,
                "f1-score": 0.9188107938500156,
                "support": 12435
            },
            "1": {
                "precision": 0.775776397515528,
                "recall": 0.6495059802392096,
                "f1-score": 0.707047834701387,
                "support": 3846
            },
            "accuracy": 0.8728579325594251,
            "macro avg": {
                "precision": 0.8362841868138087,
                "recall": 0.7957220291224194,
                "f1-score": 0.8129293142757013,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8682049166389381,
                "recall": 0.8728579325594251,
                "f1-score": 0.86878681860982,
                "support": 16281
            },
            "roc_auc": 0.9275005378984762,
            "score": 0.8728579325594251
        }
    }
}
