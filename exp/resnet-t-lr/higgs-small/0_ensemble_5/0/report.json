{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train1___db8157809a8844038097afdb279ddaa6.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.766461409278567,
                "recall": 0.7405516868365898,
                "f1-score": 0.7532838181693143,
                "support": 29582
            },
            "1": {
                "precision": 0.7753811934794697,
                "recall": 0.7987578763303084,
                "f1-score": 0.7868959577059015,
                "support": 33169
            },
            "accuracy": 0.7713183853643767,
            "macro avg": {
                "precision": 0.7709213013790184,
                "recall": 0.7696547815834491,
                "f1-score": 0.7700898879376079,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7711762396742537,
                "recall": 0.7713183853643767,
                "f1-score": 0.7710505638194085,
                "support": 62751
            },
            "roc_auc": 0.8566175196120361,
            "score": 0.7713183853643767
        },
        "val": {
            "0": {
                "precision": 0.737294201861131,
                "recall": 0.696322336398053,
                "f1-score": 0.7162227939642583,
                "support": 7396
            },
            "1": {
                "precision": 0.7419280707801907,
                "recall": 0.7787023637240714,
                "f1-score": 0.7598705501618124,
                "support": 8292
            },
            "accuracy": 0.7398648648648649,
            "macro avg": {
                "precision": 0.7396111363206609,
                "recall": 0.7375123500610622,
                "f1-score": 0.7380466720630353,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7397434650608278,
                "recall": 0.7398648648648649,
                "f1-score": 0.7392931148713286,
                "support": 15688
            },
            "roc_auc": 0.819490299250426,
            "score": 0.7398648648648649
        },
        "test": {
            "0": {
                "precision": 0.7248413417951043,
                "recall": 0.6918334234721472,
                "f1-score": 0.7079528474182303,
                "support": 9245
            },
            "1": {
                "precision": 0.7358613016873725,
                "recall": 0.7657501205981669,
                "f1-score": 0.7505082502009361,
                "support": 10365
            },
            "accuracy": 0.7309026007139214,
            "macro avg": {
                "precision": 0.7303513217412384,
                "recall": 0.7287917720351571,
                "f1-score": 0.7292305488095832,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7306660171792634,
                "recall": 0.7309026007139214,
                "f1-score": 0.7304457974357085,
                "support": 19610
            },
            "roc_auc": 0.8124664353582085,
            "score": 0.7309026007139214
        }
    }
}
