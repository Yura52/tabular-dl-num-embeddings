{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/xgboost____25e5d0acbbef45278310b4ca1540be87.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8762795623014472,
                "recall": 0.9742935635792779,
                "f1-score": 0.9226909496376138,
                "support": 5096
            },
            "1": {
                "precision": 0.8215258855585831,
                "recall": 0.4624233128834356,
                "f1-score": 0.591756624141315,
                "support": 1304
            },
            "accuracy": 0.87,
            "macro avg": {
                "precision": 0.8489027239300151,
                "recall": 0.7183584382313567,
                "f1-score": 0.7572237868894645,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8651235006650887,
                "recall": 0.87,
                "f1-score": 0.8552630808177429,
                "support": 6400
            },
            "roc_auc": 0.8884779563665959,
            "score": 0.87
        },
        "val": {
            "0": {
                "precision": 0.8746498599439776,
                "recall": 0.9803767660910518,
                "f1-score": 0.9245003700962251,
                "support": 1274
            },
            "1": {
                "precision": 0.8546511627906976,
                "recall": 0.450920245398773,
                "f1-score": 0.5903614457831325,
                "support": 326
            },
            "accuracy": 0.8725,
            "macro avg": {
                "precision": 0.8646505113673376,
                "recall": 0.7156485057449125,
                "f1-score": 0.7574309079396788,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8705751253989967,
                "recall": 0.8725,
                "f1-score": 0.8564195642674325,
                "support": 1600
            },
            "roc_auc": 0.8655748283268003,
            "score": 0.8725
        },
        "test": {
            "0": {
                "precision": 0.8651810584958217,
                "recall": 0.9748901443816698,
                "f1-score": 0.9167650531286894,
                "support": 1593
            },
            "1": {
                "precision": 0.8048780487804879,
                "recall": 0.40540540540540543,
                "f1-score": 0.5392156862745098,
                "support": 407
            },
            "accuracy": 0.859,
            "macro avg": {
                "precision": 0.8350295536381548,
                "recall": 0.6901477748935376,
                "f1-score": 0.7279903697015996,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8529093960187513,
                "recall": 0.859,
                "f1-score": 0.8399337569738639,
                "support": 2000
            },
            "roc_auc": 0.8564697208765006,
            "score": 0.859
        }
    }
}
