{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/xgboost____8eb7cbef68b74d2388519b11213a86c5.py",
    "data": "data/adult",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.902003066896684,
                "recall": 0.951858407079646,
                "f1-score": 0.9262603646384371,
                "support": 19775
            },
            "1": {
                "precision": 0.8162162162162162,
                "recall": 0.6739996811732824,
                "f1-score": 0.7383218370732559,
                "support": 6273
            },
            "accuracy": 0.8849431818181818,
            "macro avg": {
                "precision": 0.8591096415564501,
                "recall": 0.8129290441264642,
                "f1-score": 0.8322911008558465,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8813434801983357,
                "recall": 0.8849431818181818,
                "f1-score": 0.8810001380023659,
                "support": 26048
            },
            "roc_auc": 0.9435848860013103,
            "score": 0.8849431818181818
        },
        "val": {
            "0": {
                "precision": 0.8926251432938479,
                "recall": 0.9447927199191102,
                "f1-score": 0.9179683662442284,
                "support": 4945
            },
            "1": {
                "precision": 0.7865519937451134,
                "recall": 0.6415816326530612,
                "f1-score": 0.7067088162978575,
                "support": 1568
            },
            "accuracy": 0.8717948717948718,
            "macro avg": {
                "precision": 0.8395885685194806,
                "recall": 0.7931871762860857,
                "f1-score": 0.812338591271043,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8670881099002635,
                "recall": 0.8717948717948718,
                "f1-score": 0.8671077836684707,
                "support": 6513
            },
            "roc_auc": 0.930034073791296,
            "score": 0.8717948717948718
        },
        "test": {
            "0": {
                "precision": 0.8961623559929809,
                "recall": 0.9445918777643747,
                "f1-score": 0.9197400360191058,
                "support": 12435
            },
            "1": {
                "precision": 0.7829237555135475,
                "recall": 0.6461258450338013,
                "f1-score": 0.7079772079772081,
                "support": 3846
            },
            "accuracy": 0.8740863583317978,
            "macro avg": {
                "precision": 0.8395430557532642,
                "recall": 0.7953588613990881,
                "f1-score": 0.813858621998157,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8694124230991844,
                "recall": 0.8740863583317978,
                "f1-score": 0.8697160917497648,
                "support": 16281
            },
            "roc_auc": 0.9275391474042556,
            "score": 0.8740863583317978
        }
    }
}
