{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train0___a54014b9c2f7427b9ee59a9324c5d854.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7585406078556763,
                "recall": 0.7618484213372997,
                "f1-score": 0.7601909162970334,
                "support": 29582
            },
            "1": {
                "precision": 0.7867736077481841,
                "recall": 0.7837137085833158,
                "f1-score": 0.7852406772493167,
                "support": 33169
            },
            "accuracy": 0.7734060014979841,
            "macro avg": {
                "precision": 0.7726571078019302,
                "recall": 0.7727810649603077,
                "f1-score": 0.772715796773175,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7734640413218297,
                "recall": 0.7734060014979841,
                "f1-score": 0.7734317494475216,
                "support": 62751
            },
            "roc_auc": 0.857246996402969,
            "score": 0.7734060014979841
        },
        "val": {
            "0": {
                "precision": 0.7252444566864068,
                "recall": 0.7120064899945917,
                "f1-score": 0.7185645084260079,
                "support": 7396
            },
            "1": {
                "precision": 0.7472410110359559,
                "recall": 0.7594066570188133,
                "f1-score": 0.7532747173874035,
                "support": 8292
            },
            "accuracy": 0.7370601733809281,
            "macro avg": {
                "precision": 0.7362427338611813,
                "recall": 0.7357065735067025,
                "f1-score": 0.7359196129067057,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7368708863566299,
                "recall": 0.7370601733809281,
                "f1-score": 0.7369108274410444,
                "support": 15688
            },
            "roc_auc": 0.8170387615814025,
            "score": 0.7370601733809281
        },
        "test": {
            "0": {
                "precision": 0.7153796376186368,
                "recall": 0.7174689021092483,
                "f1-score": 0.7164227466652265,
                "support": 9245
            },
            "1": {
                "precision": 0.747339911007932,
                "recall": 0.7453931500241197,
                "f1-score": 0.7463652610732743,
                "support": 10365
            },
            "accuracy": 0.7322284548699644,
            "macro avg": {
                "precision": 0.7313597743132844,
                "recall": 0.731431026066684,
                "f1-score": 0.7313940038692504,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7322724593259313,
                "recall": 0.7322284548699644,
                "f1-score": 0.7322490680236873,
                "support": 19610
            },
            "roc_auc": 0.8096112864752383,
            "score": 0.7322284548699644
        }
    }
}
