{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train0___995ca4e2f4b54fe2a058fee5dcebf0d3.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8837876614060258,
                "recall": 0.967032967032967,
                "f1-score": 0.9235382308845577,
                "support": 5096
            },
            "1": {
                "precision": 0.7961165048543689,
                "recall": 0.5030674846625767,
                "f1-score": 0.6165413533834587,
                "support": 1304
            },
            "accuracy": 0.8725,
            "macro avg": {
                "precision": 0.8399520831301974,
                "recall": 0.7350502258477718,
                "f1-score": 0.7700397921340082,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8659246632586257,
                "recall": 0.8725,
                "f1-score": 0.8609876170937087,
                "support": 6400
            },
            "roc_auc": 0.8875040931898951,
            "score": 0.8725
        },
        "val": {
            "0": {
                "precision": 0.8802867383512545,
                "recall": 0.9638932496075353,
                "f1-score": 0.9201948295241663,
                "support": 1274
            },
            "1": {
                "precision": 0.775609756097561,
                "recall": 0.48773006134969327,
                "f1-score": 0.5988700564971752,
                "support": 326
            },
            "accuracy": 0.866875,
            "macro avg": {
                "precision": 0.8279482472244077,
                "recall": 0.7258116554786143,
                "f1-score": 0.7595324430106707,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8589588032170644,
                "recall": 0.866875,
                "f1-score": 0.8547249070199169,
                "support": 1600
            },
            "roc_auc": 0.8646598799973035,
            "score": 0.866875
        },
        "test": {
            "0": {
                "precision": 0.876070816676185,
                "recall": 0.9629629629629629,
                "f1-score": 0.9174641148325358,
                "support": 1593
            },
            "1": {
                "precision": 0.7630522088353414,
                "recall": 0.4668304668304668,
                "f1-score": 0.5792682926829269,
                "support": 407
            },
            "accuracy": 0.862,
            "macro avg": {
                "precision": 0.8195615127557632,
                "recall": 0.7148967148967149,
                "f1-score": 0.7483662037577313,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8530715299805733,
                "recall": 0.862,
                "f1-score": 0.8486412650250903,
                "support": 2000
            },
            "roc_auc": 0.8581755869891463,
            "score": 0.862
        }
    }
}
