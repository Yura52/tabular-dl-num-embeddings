{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train0___995ca4e2f4b54fe2a058fee5dcebf0d3.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8782209671726086,
                "recall": 0.9764521193092621,
                "f1-score": 0.9247351793346962,
                "support": 5096
            },
            "1": {
                "precision": 0.8365122615803815,
                "recall": 0.4708588957055215,
                "f1-score": 0.6025515210991167,
                "support": 1304
            },
            "accuracy": 0.8734375,
            "macro avg": {
                "precision": 0.8573666143764951,
                "recall": 0.7236555075073918,
                "f1-score": 0.7636433502169064,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8697228184081922,
                "recall": 0.8734375,
                "f1-score": 0.8590902589691969,
                "support": 6400
            },
            "roc_auc": 0.8900360020128862,
            "score": 0.8734375
        },
        "val": {
            "0": {
                "precision": 0.8748241912798875,
                "recall": 0.9764521193092621,
                "f1-score": 0.9228486646884273,
                "support": 1274
            },
            "1": {
                "precision": 0.8314606741573034,
                "recall": 0.4539877300613497,
                "f1-score": 0.5873015873015872,
                "support": 326
            },
            "accuracy": 0.87,
            "macro avg": {
                "precision": 0.8531424327185955,
                "recall": 0.7152199246853059,
                "f1-score": 0.7550751259950073,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.865988874666161,
                "recall": 0.87,
                "f1-score": 0.8544809476708586,
                "support": 1600
            },
            "roc_auc": 0.8673854629156994,
            "score": 0.87
        },
        "test": {
            "0": {
                "precision": 0.8673754896474538,
                "recall": 0.9730069052102951,
                "f1-score": 0.9171597633136095,
                "support": 1593
            },
            "1": {
                "precision": 0.7981220657276995,
                "recall": 0.4176904176904177,
                "f1-score": 0.5483870967741936,
                "support": 407
            },
            "accuracy": 0.86,
            "macro avg": {
                "precision": 0.8327487776875766,
                "recall": 0.6953486614503563,
                "f1-score": 0.7327734300439015,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8532824178797838,
                "recall": 0.86,
                "f1-score": 0.8421145256728383,
                "support": 2000
            },
            "roc_auc": 0.8595853172124359,
            "score": 0.86
        }
    }
}
