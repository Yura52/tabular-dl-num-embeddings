{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train0___65c249c7d3ae40d48b1f48af106cd613.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7536905130587385,
                "recall": 0.7404164694746805,
                "f1-score": 0.7469945262009106,
                "support": 29582
            },
            "1": {
                "precision": 0.7720688631641437,
                "recall": 0.7841960867074678,
                "f1-score": 0.7780852241283895,
                "support": 33169
            },
            "accuracy": 0.7635575528676833,
            "macro avg": {
                "precision": 0.762879688111441,
                "recall": 0.7623062780910741,
                "f1-score": 0.76253987516465,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7634049637391449,
                "recall": 0.7635575528676833,
                "f1-score": 0.7634284851745771,
                "support": 62751
            },
            "roc_auc": 0.8486727872107686,
            "score": 0.7635575528676833
        },
        "val": {
            "0": {
                "precision": 0.7309594460929772,
                "recall": 0.6994321254732287,
                "f1-score": 0.7148483382850824,
                "support": 7396
            },
            "1": {
                "precision": 0.7418418302171641,
                "recall": 0.7703810902074288,
                "f1-score": 0.7558421581967698,
                "support": 8292
            },
            "accuracy": 0.7369326874043856,
            "macro avg": {
                "precision": 0.7364006381550707,
                "recall": 0.7349066078403288,
                "f1-score": 0.7353452482409262,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7367114048613197,
                "recall": 0.7369326874043856,
                "f1-score": 0.7365159029655842,
                "support": 15688
            },
            "roc_auc": 0.8189762976662787,
            "score": 0.7369326874043856
        },
        "test": {
            "0": {
                "precision": 0.7241149705914993,
                "recall": 0.7057869118442401,
                "f1-score": 0.7148334794040315,
                "support": 9245
            },
            "1": {
                "precision": 0.743372016227946,
                "recall": 0.760154365653642,
                "f1-score": 0.7516695287158939,
                "support": 10365
            },
            "accuracy": 0.7345232024477307,
            "macro avg": {
                "precision": 0.7337434934097227,
                "recall": 0.7329706387489411,
                "f1-score": 0.7332515040599628,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7342934141418191,
                "recall": 0.7345232024477307,
                "f1-score": 0.7343034259169052,
                "support": 19610
            },
            "roc_auc": 0.8136605620122428,
            "score": 0.7345232024477307
        }
    }
}
