{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train0___d13e50d9fcc342a9b6edb521ef255c54.py",
    "data": "data/adult",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9018545632015618,
                "recall": 0.9344627054361567,
                "f1-score": 0.9178691170992177,
                "support": 19775
            },
            "1": {
                "precision": 0.7668225980568549,
                "recall": 0.6794197353738243,
                "f1-score": 0.7204800946665539,
                "support": 6273
            },
            "accuracy": 0.8730420761670762,
            "macro avg": {
                "precision": 0.8343385806292083,
                "recall": 0.8069412204049905,
                "f1-score": 0.8191746058828858,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8693355399616682,
                "recall": 0.8730420761670762,
                "f1-score": 0.8703329785196685,
                "support": 26048
            },
            "roc_auc": 0.9305760545818442,
            "score": 0.8730420761670762
        },
        "val": {
            "0": {
                "precision": 0.8919867420549815,
                "recall": 0.9251769464105156,
                "f1-score": 0.9082787373436569,
                "support": 4945
            },
            "1": {
                "precision": 0.7326589595375722,
                "recall": 0.6466836734693877,
                "f1-score": 0.6869918699186991,
                "support": 1568
            },
            "accuracy": 0.8581298940580377,
            "macro avg": {
                "precision": 0.8123228507962769,
                "recall": 0.7859303099399517,
                "f1-score": 0.7976353036311781,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8536286946133573,
                "recall": 0.8581298940580377,
                "f1-score": 0.8550040853979585,
                "support": 6513
            },
            "roc_auc": 0.9149781525350281,
            "score": 0.8581298940580377
        },
        "test": {
            "0": {
                "precision": 0.8913936013633899,
                "recall": 0.925371934057097,
                "f1-score": 0.9080650252525252,
                "support": 12435
            },
            "1": {
                "precision": 0.7247924080664294,
                "recall": 0.6354654186167447,
                "f1-score": 0.6771958991410363,
                "support": 3846
            },
            "accuracy": 0.8568883975185799,
            "macro avg": {
                "precision": 0.8080930047149096,
                "recall": 0.7804186763369207,
                "f1-score": 0.7926304621967808,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8520380218891493,
                "recall": 0.8568883975185799,
                "f1-score": 0.8535276713415377,
                "support": 16281
            },
            "roc_auc": 0.9103928781196282,
            "score": 0.8568883975185799
        }
    }
}
