{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train0___3a2ea470f49644889e6f6452af0687d6.py",
    "data": "data/covtype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9822490452305851,
                "recall": 0.9807638407411232,
                "f1-score": 0.9815058811371797,
                "support": 135578
            },
            "1": {
                "precision": 0.986295995446734,
                "recall": 0.9844301535474762,
                "f1-score": 0.9853621912272518,
                "support": 181312
            },
            "2": {
                "precision": 0.9924122807017544,
                "recall": 0.9888558692421991,
                "f1-score": 0.990630883061162,
                "support": 22882
            },
            "3": {
                "precision": 0.9783845278725825,
                "recall": 0.9778283115406481,
                "f1-score": 0.9781063406312198,
                "support": 1759
            },
            "4": {
                "precision": 0.9243226409218313,
                "recall": 0.977119341563786,
                "f1-score": 0.9499879971193087,
                "support": 6075
            },
            "5": {
                "precision": 0.9789089614665836,
                "recall": 0.9896536212325686,
                "f1-score": 0.984251968503937,
                "support": 11115
            },
            "6": {
                "precision": 0.974262492474413,
                "recall": 0.9862867591040683,
                "f1-score": 0.9802377527068978,
                "support": 13126
            },
            "accuracy": 0.9834367360769348,
            "macro avg": {
                "precision": 0.973833706302069,
                "recall": 0.9835625567102672,
                "f1-score": 0.9785832877695653,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.9835013309204491,
                "recall": 0.9834367360769348,
                "f1-score": 0.9834540478810898,
                "support": 371847
            },
            "score": 0.9834367360769348
        },
        "val": {
            "0": {
                "precision": 0.9657629423764894,
                "recall": 0.9637398949666608,
                "f1-score": 0.9647503581080084,
                "support": 33894
            },
            "1": {
                "precision": 0.9723192571302233,
                "recall": 0.9702170843628662,
                "f1-score": 0.9712670332825372,
                "support": 45328
            },
            "2": {
                "precision": 0.9725476481902431,
                "recall": 0.9722076560041951,
                "f1-score": 0.9723776223776224,
                "support": 5721
            },
            "3": {
                "precision": 0.9236111111111112,
                "recall": 0.908883826879271,
                "f1-score": 0.9161882893226176,
                "support": 439
            },
            "4": {
                "precision": 0.8700564971751412,
                "recall": 0.9124423963133641,
                "f1-score": 0.890745501285347,
                "support": 1519
            },
            "5": {
                "precision": 0.9399929403459231,
                "recall": 0.9582583663188197,
                "f1-score": 0.9490377761938703,
                "support": 2779
            },
            "6": {
                "precision": 0.9543817527010804,
                "recall": 0.9689213893967094,
                "f1-score": 0.9615966132446326,
                "support": 3282
            },
            "accuracy": 0.9663410856048708,
            "macro avg": {
                "precision": 0.9426674498614588,
                "recall": 0.9506672306059837,
                "f1-score": 0.946566170544948,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9664422445943176,
                "recall": 0.9663410856048708,
                "f1-score": 0.9663776407579742,
                "support": 92962
            },
            "score": 0.9663410856048708
        },
        "test": {
            "0": {
                "precision": 0.9663302056677092,
                "recall": 0.9625896903323263,
                "f1-score": 0.9644563212410727,
                "support": 42368
            },
            "1": {
                "precision": 0.9711665871627709,
                "recall": 0.9701381902896172,
                "f1-score": 0.9706521163320442,
                "support": 56661
            },
            "2": {
                "precision": 0.9692608634902893,
                "recall": 0.9700741155083206,
                "f1-score": 0.9696673189823876,
                "support": 7151
            },
            "3": {
                "precision": 0.9094269870609981,
                "recall": 0.8961748633879781,
                "f1-score": 0.9027522935779816,
                "support": 549
            },
            "4": {
                "precision": 0.8643643643643644,
                "recall": 0.9094260136914165,
                "f1-score": 0.8863228124198101,
                "support": 1899
            },
            "5": {
                "precision": 0.9433106575963719,
                "recall": 0.9582493521451195,
                "f1-score": 0.9507213255249249,
                "support": 3473
            },
            "6": {
                "precision": 0.9561571633924293,
                "recall": 0.9729400292540225,
                "f1-score": 0.9644755920734653,
                "support": 4102
            },
            "accuracy": 0.9657840159032038,
            "macro avg": {
                "precision": 0.9400024041049905,
                "recall": 0.9485131792298287,
                "f1-score": 0.9441496828788123,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9658865134778852,
                "recall": 0.9657840159032038,
                "f1-score": 0.9658198846162985,
                "support": 116203
            },
            "score": 0.9657840159032038
        }
    }
}
