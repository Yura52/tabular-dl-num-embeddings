{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train0___64bea6b3d61a4e2d88d97c947cc59c38.py",
    "data": "data/covtype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9942472288480426,
                "recall": 0.9930372184277685,
                "f1-score": 0.9936418552645659,
                "support": 135578
            },
            "1": {
                "precision": 0.9945244417023809,
                "recall": 0.9957421461348394,
                "f1-score": 0.995132921404673,
                "support": 181312
            },
            "2": {
                "precision": 0.9956744003145891,
                "recall": 0.9958919674853597,
                "f1-score": 0.9957831720159933,
                "support": 22882
            },
            "3": {
                "precision": 0.9824858757062147,
                "recall": 0.9886299033541786,
                "f1-score": 0.9855483139699632,
                "support": 1759
            },
            "4": {
                "precision": 0.9809648834919593,
                "recall": 0.9840329218106996,
                "f1-score": 0.982496507519106,
                "support": 6075
            },
            "5": {
                "precision": 0.9938689027139122,
                "recall": 0.9917228969860549,
                "f1-score": 0.9927947401603171,
                "support": 11115
            },
            "6": {
                "precision": 0.991652626742227,
                "recall": 0.9865153131190004,
                "f1-score": 0.9890772991139627,
                "support": 13126
            },
            "accuracy": 0.9940943452549033,
            "macro avg": {
                "precision": 0.9904883370741894,
                "recall": 0.9907960524739858,
                "f1-score": 0.9906392584926546,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.9940946882711572,
                "recall": 0.9940943452549033,
                "f1-score": 0.9940938455153784,
                "support": 371847
            },
            "score": 0.9940943452549033
        },
        "val": {
            "0": {
                "precision": 0.971567062717976,
                "recall": 0.969847170590665,
                "f1-score": 0.9707063548310891,
                "support": 33894
            },
            "1": {
                "precision": 0.9747423588478816,
                "recall": 0.976548711613131,
                "f1-score": 0.9756446991404012,
                "support": 45328
            },
            "2": {
                "precision": 0.9686199722607489,
                "recall": 0.9765775214123406,
                "f1-score": 0.9725824701888763,
                "support": 5721
            },
            "3": {
                "precision": 0.9255813953488372,
                "recall": 0.9066059225512528,
                "f1-score": 0.9159953970080552,
                "support": 439
            },
            "4": {
                "precision": 0.9113924050632911,
                "recall": 0.9005924950625411,
                "f1-score": 0.9059602649006623,
                "support": 1519
            },
            "5": {
                "precision": 0.9549909255898367,
                "recall": 0.9467434328895286,
                "f1-score": 0.9508492952656307,
                "support": 2779
            },
            "6": {
                "precision": 0.9708767627222563,
                "recall": 0.9649603900060938,
                "f1-score": 0.9679095354523227,
                "support": 3282
            },
            "accuracy": 0.9712355586153482,
            "macro avg": {
                "precision": 0.9539672689358326,
                "recall": 0.9488393777322218,
                "f1-score": 0.9513782881124341,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9712136479447677,
                "recall": 0.9712355586153482,
                "f1-score": 0.9712210724145344,
                "support": 92962
            },
            "score": 0.9712355586153482
        },
        "test": {
            "0": {
                "precision": 0.9723335150897323,
                "recall": 0.968041918429003,
                "f1-score": 0.9701829708216537,
                "support": 42368
            },
            "1": {
                "precision": 0.9730784786087323,
                "recall": 0.9766506062370943,
                "f1-score": 0.9748612701488593,
                "support": 56661
            },
            "2": {
                "precision": 0.9662330473290894,
                "recall": 0.9763669416864774,
                "f1-score": 0.9712735619392084,
                "support": 7151
            },
            "3": {
                "precision": 0.9117647058823529,
                "recall": 0.9034608378870674,
                "f1-score": 0.9075937785910339,
                "support": 549
            },
            "4": {
                "precision": 0.9082125603864735,
                "recall": 0.8909952606635071,
                "f1-score": 0.8995215311004785,
                "support": 1899
            },
            "5": {
                "precision": 0.953792502179599,
                "recall": 0.9450043190325367,
                "f1-score": 0.9493780734741106,
                "support": 3473
            },
            "6": {
                "precision": 0.9722971316499142,
                "recall": 0.9668454412481716,
                "f1-score": 0.9695636230289695,
                "support": 4102
            },
            "accuracy": 0.9704568728862422,
            "macro avg": {
                "precision": 0.9511017058751277,
                "recall": 0.9467664750262653,
                "f1-score": 0.9489106870149021,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9704318927654408,
                "recall": 0.9704568728862422,
                "f1-score": 0.9704371159088003,
                "support": 116203
            },
            "score": 0.9704568728862422
        }
    }
}
