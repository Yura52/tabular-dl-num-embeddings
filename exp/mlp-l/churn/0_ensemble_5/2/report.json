{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train0___2b6d7de27b694321a66f31fedf0f3853.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8794835007173601,
                "recall": 0.9623233908948194,
                "f1-score": 0.9190404797601199,
                "support": 5096
            },
            "1": {
                "precision": 0.7669902912621359,
                "recall": 0.48466257668711654,
                "f1-score": 0.5939849624060151,
                "support": 1304
            },
            "accuracy": 0.865,
            "macro avg": {
                "precision": 0.823236895989748,
                "recall": 0.723492983790968,
                "f1-score": 0.7565127210830676,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8565630092908582,
                "recall": 0.865,
                "f1-score": 0.852810418099221,
                "support": 6400
            },
            "roc_auc": 0.8765989023027805,
            "score": 0.865
        },
        "val": {
            "0": {
                "precision": 0.8810888252148997,
                "recall": 0.9654631083202512,
                "f1-score": 0.9213483146067416,
                "support": 1274
            },
            "1": {
                "precision": 0.7843137254901961,
                "recall": 0.49079754601226994,
                "f1-score": 0.6037735849056604,
                "support": 326
            },
            "accuracy": 0.86875,
            "macro avg": {
                "precision": 0.8327012753525479,
                "recall": 0.7281303271662606,
                "f1-score": 0.7625609497562009,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8613708986459914,
                "recall": 0.86875,
                "f1-score": 0.8566424634301464,
                "support": 1600
            },
            "roc_auc": 0.8631285454247769,
            "score": 0.86875
        },
        "test": {
            "0": {
                "precision": 0.8715336728919072,
                "recall": 0.9667294413057125,
                "f1-score": 0.9166666666666666,
                "support": 1593
            },
            "1": {
                "precision": 0.7725321888412017,
                "recall": 0.44226044226044225,
                "f1-score": 0.5625,
                "support": 407
            },
            "accuracy": 0.86,
            "macro avg": {
                "precision": 0.8220329308665544,
                "recall": 0.7044949417830774,
                "f1-score": 0.7395833333333333,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8513868708875887,
                "recall": 0.86,
                "f1-score": 0.84459375,
                "support": 2000
            },
            "roc_auc": 0.8584331635179093,
            "score": 0.86
        }
    }
}
