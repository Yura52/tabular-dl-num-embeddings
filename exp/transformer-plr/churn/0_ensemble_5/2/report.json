{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train3___1e1670a9824b4173bc08f9da76214db1.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8833095067905646,
                "recall": 0.9699764521193093,
                "f1-score": 0.9246165357276469,
                "support": 5096
            },
            "1": {
                "precision": 0.8097014925373134,
                "recall": 0.49923312883435583,
                "f1-score": 0.6176470588235293,
                "support": 1304
            },
            "accuracy": 0.8740625,
            "macro avg": {
                "precision": 0.846505499663939,
                "recall": 0.7346047904768326,
                "f1-score": 0.7711317972755881,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8683118738864647,
                "recall": 0.8740625,
                "f1-score": 0.862071504808433,
                "support": 6400
            },
            "roc_auc": 0.8896751391684565,
            "score": 0.8740625
        },
        "val": {
            "0": {
                "precision": 0.8780141843971632,
                "recall": 0.9717425431711146,
                "f1-score": 0.9225037257824144,
                "support": 1274
            },
            "1": {
                "precision": 0.8105263157894737,
                "recall": 0.4723926380368098,
                "f1-score": 0.5968992248062015,
                "support": 326
            },
            "accuracy": 0.87,
            "macro avg": {
                "precision": 0.8442702500933184,
                "recall": 0.7220675906039622,
                "f1-score": 0.7597014752943079,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8642635311683464,
                "recall": 0.87,
                "f1-score": 0.8561618087085111,
                "support": 1600
            },
            "roc_auc": 0.8710910036501623,
            "score": 0.87
        },
        "test": {
            "0": {
                "precision": 0.8739400791407574,
                "recall": 0.970495919648462,
                "f1-score": 0.9196906603212374,
                "support": 1593
            },
            "1": {
                "precision": 0.7965367965367965,
                "recall": 0.4520884520884521,
                "f1-score": 0.5768025078369906,
                "support": 407
            },
            "accuracy": 0.865,
            "macro avg": {
                "precision": 0.8352384378387769,
                "recall": 0.7112921858684571,
                "f1-score": 0.7482465840791139,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8581885111308514,
                "recall": 0.865,
                "f1-score": 0.8499129212906932,
                "support": 2000
            },
            "roc_auc": 0.8602469958402162,
            "score": 0.865
        }
    }
}
