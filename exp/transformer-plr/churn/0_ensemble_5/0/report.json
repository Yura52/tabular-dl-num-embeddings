{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train3___1e1670a9824b4173bc08f9da76214db1.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8865644724977457,
                "recall": 0.9646781789638933,
                "f1-score": 0.9239733107790622,
                "support": 5096
            },
            "1": {
                "precision": 0.7894736842105263,
                "recall": 0.5176380368098159,
                "f1-score": 0.6252894858730894,
                "support": 1304
            },
            "accuracy": 0.87359375,
            "macro avg": {
                "precision": 0.838019078354136,
                "recall": 0.7411581078868545,
                "f1-score": 0.7746313983260757,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8667822243842247,
                "recall": 0.87359375,
                "f1-score": 0.8631164814544704,
                "support": 6400
            },
            "roc_auc": 0.8903700785410907,
            "score": 0.87359375
        },
        "val": {
            "0": {
                "precision": 0.8812589413447782,
                "recall": 0.967032967032967,
                "f1-score": 0.9221556886227545,
                "support": 1274
            },
            "1": {
                "precision": 0.7920792079207921,
                "recall": 0.49079754601226994,
                "f1-score": 0.606060606060606,
                "support": 326
            },
            "accuracy": 0.87,
            "macro avg": {
                "precision": 0.8366690746327852,
                "recall": 0.7289152565226185,
                "f1-score": 0.7641081473416802,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8630885706596411,
                "recall": 0.87,
                "f1-score": 0.8577513155507168,
                "support": 1600
            },
            "roc_auc": 0.8729040459978233,
            "score": 0.87
        },
        "test": {
            "0": {
                "precision": 0.8786491127647396,
                "recall": 0.9635907093534212,
                "f1-score": 0.9191616766467064,
                "support": 1593
            },
            "1": {
                "precision": 0.7707509881422925,
                "recall": 0.47911547911547914,
                "f1-score": 0.5909090909090909,
                "support": 407
            },
            "accuracy": 0.865,
            "macro avg": {
                "precision": 0.824700050453516,
                "recall": 0.7213530942344502,
                "f1-score": 0.7550353837778987,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8566918444040716,
                "recall": 0.865,
                "f1-score": 0.8523622754491017,
                "support": 2000
            },
            "roc_auc": 0.8608161320025727,
            "score": 0.865
        }
    }
}
