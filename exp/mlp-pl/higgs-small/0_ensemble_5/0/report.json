{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train3___f57a7bfd63b340018b3f1534c7ce2e25.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7356976265605707,
                "recall": 0.7251031032384558,
                "f1-score": 0.7303619462698765,
                "support": 29582
            },
            "1": {
                "precision": 0.7579401696681054,
                "recall": 0.7676746359552594,
                "f1-score": 0.7627763465340603,
                "support": 33169
            },
            "accuracy": 0.7476056158467594,
            "macro avg": {
                "precision": 0.746818898114338,
                "recall": 0.7463888695968577,
                "f1-score": 0.7465691464019684,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7474546170839699,
                "recall": 0.7476056158467594,
                "f1-score": 0.7474955894367219,
                "support": 62751
            },
            "roc_auc": 0.831000625253414,
            "score": 0.7476056158467594
        },
        "val": {
            "0": {
                "precision": 0.7264416315049227,
                "recall": 0.6983504597079503,
                "f1-score": 0.7121191231214672,
                "support": 7396
            },
            "1": {
                "precision": 0.7399160643506645,
                "recall": 0.7654365653642065,
                "f1-score": 0.7524599881446354,
                "support": 8292
            },
            "accuracy": 0.7338092809790923,
            "macro avg": {
                "precision": 0.7331788479277936,
                "recall": 0.7318935125360784,
                "f1-score": 0.7322895556330513,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7335636354032457,
                "recall": 0.7338092809790923,
                "f1-score": 0.7334415640171909,
                "support": 15688
            },
            "roc_auc": 0.8139887905667057,
            "score": 0.7338092809790923
        },
        "test": {
            "0": {
                "precision": 0.7177570093457943,
                "recall": 0.7061114115738237,
                "f1-score": 0.711886586695747,
                "support": 9245
            },
            "1": {
                "precision": 0.7416072277698526,
                "recall": 0.7523396044380125,
                "f1-score": 0.746934865900383,
                "support": 10365
            },
            "accuracy": 0.7305456399796022,
            "macro avg": {
                "precision": 0.7296821185578235,
                "recall": 0.7292255080059181,
                "f1-score": 0.729410726298065,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7303632058764096,
                "recall": 0.7305456399796022,
                "f1-score": 0.730411595056586,
                "support": 19610
            },
            "roc_auc": 0.8078086093394248,
            "score": 0.7305456399796022
        }
    }
}
