{
    "program": "bin/train3___4665c41d2e1a4488a892ae57ca843643.py",
    "environment": {
        "CUDA_VISIBLE_DEVICES": "0",
        "gpus": {
            "driver": "460.106.00",
            "devices": [
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11554717696,
                    "memory_free": 11550654464,
                    "memory_used": 4063232,
                    "utilization": 0
                },
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11552096256,
                    "memory_free": 9978314752,
                    "memory_used": 1573781504,
                    "utilization": 29
                }
            ]
        },
        "torch.version.cuda": "11.1",
        "torch.backends.cudnn.version()": 8005,
        "torch.cuda.nccl.version()": [
            2,
            10,
            3
        ]
    },
    "config": {
        "seed": 6,
        "data": {
            "path": "data/eye",
            "T": {
                "seed": 0,
                "normalization": "standard",
                "num_nan_policy": null,
                "cat_nan_policy": null,
                "cat_min_frequency": null,
                "cat_encoding": null,
                "y_policy": "default"
            },
            "T_cache": true
        },
        "model": {
            "d_num_embedding": 46,
            "num_embedding_arch": [
                "positional",
                "linear"
            ],
            "d_cat_embedding": null,
            "mlp": {
                "d_layers": [
                    998,
                    690
                ],
                "dropout": 0.0019001161380328927
            },
            "resnet": null,
            "transformer": null,
            "transformer_default": false,
            "transformer_baseline": true,
            "periodic_sigma": null,
            "positional_encoding": {
                "n": 63,
                "sigma": 11.752208390515277,
                "trainable": true,
                "initialization": "normal"
            },
            "fourier_features": null,
            "memory_efficient": false
        },
        "training": {
            "batch_size": 128,
            "lr": 0.003994660903555985,
            "weight_decay": 1.0727969022300632e-06,
            "optimizer": "AdamW",
            "patience": 16,
            "n_epochs": Infinity,
            "eval_batch_size": 8192
        },
        "bins": null
    },
    "prediction_type": "logits",
    "epoch_size": 55,
    "n_parameters": 2039519,
    "best_epoch": 66,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9995884773662551,
                "recall": 0.9979457682826622,
                "f1-score": 0.998766447368421,
                "support": 2434
            },
            "1": {
                "precision": 0.9981678270428729,
                "recall": 0.9988998899889989,
                "f1-score": 0.998533724340176,
                "support": 2727
            },
            "2": {
                "precision": 0.99836867862969,
                "recall": 0.9994556341861731,
                "f1-score": 0.9989118607181721,
                "support": 1837
            },
            "accuracy": 0.9987139182623607,
            "macro avg": {
                "precision": 0.9987083276796059,
                "recall": 0.9987670974859447,
                "f1-score": 0.9987373441422563,
                "support": 6998
            },
            "weighted avg": {
                "precision": 0.9987146728919862,
                "recall": 0.9987139182623607,
                "f1-score": 0.9987139307387366,
                "support": 6998
            },
            "score": 0.9987139182623607
        },
        "val": {
            "0": {
                "precision": 0.825,
                "recall": 0.812807881773399,
                "f1-score": 0.8188585607940446,
                "support": 609
            },
            "1": {
                "precision": 0.8350364963503649,
                "recall": 0.8387096774193549,
                "f1-score": 0.8368690563277249,
                "support": 682
            },
            "2": {
                "precision": 0.9032258064516129,
                "recall": 0.9150326797385621,
                "f1-score": 0.9090909090909091,
                "support": 459
            },
            "accuracy": 0.8497142857142858,
            "macro avg": {
                "precision": 0.8544207676006592,
                "recall": 0.8555167463104386,
                "f1-score": 0.8549395087375595,
                "support": 1750
            },
            "weighted avg": {
                "precision": 0.8494288775269937,
                "recall": 0.8497142857142858,
                "f1-score": 0.8495441641210336,
                "support": 1750
            },
            "score": 0.8497142857142858
        },
        "test": {
            "0": {
                "precision": 0.8326241134751773,
                "recall": 0.771353482260184,
                "f1-score": 0.800818553888131,
                "support": 761
            },
            "1": {
                "precision": 0.7944444444444444,
                "recall": 0.8382180539273154,
                "f1-score": 0.8157444381061039,
                "support": 853
            },
            "2": {
                "precision": 0.869639794168096,
                "recall": 0.8832752613240418,
                "f1-score": 0.8764044943820225,
                "support": 574
            },
            "accuracy": 0.826782449725777,
            "macro avg": {
                "precision": 0.8322361173625725,
                "recall": 0.8309489325038472,
                "f1-score": 0.8309891621254191,
                "support": 2188
            },
            "weighted avg": {
                "precision": 0.8274503214434223,
                "recall": 0.826782449725777,
                "f1-score": 0.8264666841812865,
                "support": 2188
            },
            "score": 0.826782449725777
        }
    },
    "time": "0:00:14"
}
