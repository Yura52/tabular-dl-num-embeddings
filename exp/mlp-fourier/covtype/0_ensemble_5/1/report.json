{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train3___a144c8aa6f5b402191e8e0725221acf5.py",
    "data": "data/covtype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9947313194608655,
                "recall": 0.9928970776969714,
                "f1-score": 0.9938133522328778,
                "support": 135578
            },
            "1": {
                "precision": 0.9940959287769824,
                "recall": 0.9964370808330392,
                "f1-score": 0.9952651280398622,
                "support": 181312
            },
            "2": {
                "precision": 0.9976391378481179,
                "recall": 0.9972467441657198,
                "f1-score": 0.9974429024150366,
                "support": 22882
            },
            "3": {
                "precision": 0.9960136674259681,
                "recall": 0.9943149516770893,
                "f1-score": 0.995163584637269,
                "support": 1759
            },
            "4": {
                "precision": 0.989351081530782,
                "recall": 0.9787654320987654,
                "f1-score": 0.9840297889946213,
                "support": 6075
            },
            "5": {
                "precision": 0.9949667445622865,
                "recall": 0.9959514170040485,
                "f1-score": 0.9954588372824962,
                "support": 11115
            },
            "6": {
                "precision": 0.9950057625816365,
                "recall": 0.9865914977906445,
                "f1-score": 0.9907807658467541,
                "support": 13126
            },
            "accuracy": 0.9945353868661035,
            "macro avg": {
                "precision": 0.9945433774552341,
                "recall": 0.9917434573237541,
                "f1-score": 0.993136337064131,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.9945353317016847,
                "recall": 0.9945353868661035,
                "f1-score": 0.9945332706184861,
                "support": 371847
            },
            "score": 0.9945353868661035
        },
        "val": {
            "0": {
                "precision": 0.9702536146006162,
                "recall": 0.9661887059656576,
                "f1-score": 0.9682168938296424,
                "support": 33894
            },
            "1": {
                "precision": 0.9715709518791711,
                "recall": 0.9763722202612072,
                "f1-score": 0.9739656690140844,
                "support": 45328
            },
            "2": {
                "precision": 0.9678428645923866,
                "recall": 0.9732564237021499,
                "f1-score": 0.9705420951716924,
                "support": 5721
            },
            "3": {
                "precision": 0.9128440366972477,
                "recall": 0.9066059225512528,
                "f1-score": 0.9097142857142857,
                "support": 439
            },
            "4": {
                "precision": 0.9140302613480055,
                "recall": 0.8749177090190915,
                "f1-score": 0.8940464177598385,
                "support": 1519
            },
            "5": {
                "precision": 0.9487364620938629,
                "recall": 0.9456639078805326,
                "f1-score": 0.9471976932780682,
                "support": 2779
            },
            "6": {
                "precision": 0.9701078582434515,
                "recall": 0.9591712370505789,
                "f1-score": 0.964608549103723,
                "support": 3282
            },
            "accuracy": 0.968955056904972,
            "macro avg": {
                "precision": 0.9507694356363915,
                "recall": 0.9431680180614956,
                "f1-score": 0.9468988005530478,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9689094067080846,
                "recall": 0.968955056904972,
                "f1-score": 0.9689191207030131,
                "support": 92962
            },
            "score": 0.968955056904972
        },
        "test": {
            "0": {
                "precision": 0.9702458569430286,
                "recall": 0.9659176737160121,
                "f1-score": 0.9680769276260541,
                "support": 42368
            },
            "1": {
                "precision": 0.9704277014338616,
                "recall": 0.9758740579940347,
                "f1-score": 0.9731432594156988,
                "support": 56661
            },
            "2": {
                "precision": 0.9649147136319511,
                "recall": 0.9730107677247938,
                "f1-score": 0.968945829271689,
                "support": 7151
            },
            "3": {
                "precision": 0.9080882352941176,
                "recall": 0.8998178506375227,
                "f1-score": 0.9039341262580054,
                "support": 549
            },
            "4": {
                "precision": 0.9222595078299777,
                "recall": 0.8683517640863613,
                "f1-score": 0.8944941687008409,
                "support": 1899
            },
            "5": {
                "precision": 0.9481309765285425,
                "recall": 0.9421249640080622,
                "f1-score": 0.9451184286539572,
                "support": 3473
            },
            "6": {
                "precision": 0.9743273265860282,
                "recall": 0.962213554363725,
                "f1-score": 0.9682325524346868,
                "support": 4102
            },
            "accuracy": 0.9684603667719422,
            "macro avg": {
                "precision": 0.9511991883210724,
                "recall": 0.9410443760757874,
                "f1-score": 0.9459921846229904,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9684117139555214,
                "recall": 0.9684603667719422,
                "f1-score": 0.9684145470514208,
                "support": 116203
            },
            "score": 0.9684603667719422
        }
    }
}
