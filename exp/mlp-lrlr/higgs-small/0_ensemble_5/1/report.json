{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train0___e31e1764f74c438093539566a5fee041.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7453468412372521,
                "recall": 0.7485971198701913,
                "f1-score": 0.7469684448417182,
                "support": 29582
            },
            "1": {
                "precision": 0.774909200968523,
                "recall": 0.7718954445415901,
                "f1-score": 0.7733993867903154,
                "support": 33169
            },
            "accuracy": 0.7609121766983793,
            "macro avg": {
                "precision": 0.7601280211028876,
                "recall": 0.7602462822058906,
                "f1-score": 0.7601839158160169,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7609729493459122,
                "recall": 0.7609121766983793,
                "f1-score": 0.7609393443252805,
                "support": 62751
            },
            "roc_auc": 0.8445244114739129,
            "score": 0.7609121766983793
        },
        "val": {
            "0": {
                "precision": 0.7230896780433882,
                "recall": 0.7075446187128177,
                "f1-score": 0.7152326932276363,
                "support": 7396
            },
            "1": {
                "precision": 0.7440539581114661,
                "recall": 0.7583212735166426,
                "f1-score": 0.7511198709908619,
                "support": 8292
            },
            "accuracy": 0.734382967873534,
            "macro avg": {
                "precision": 0.7335718180774271,
                "recall": 0.7329329461147301,
                "f1-score": 0.7331762821092491,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7341704920620331,
                "recall": 0.734382967873534,
                "f1-score": 0.7342011071754095,
                "support": 15688
            },
            "roc_auc": 0.8137126589202075,
            "score": 0.734382967873534
        },
        "test": {
            "0": {
                "precision": 0.7077689890562358,
                "recall": 0.7065440778799351,
                "f1-score": 0.7071560030312872,
                "support": 9245
            },
            "1": {
                "precision": 0.7386571621231095,
                "recall": 0.7397973950795947,
                "f1-score": 0.7392268389087053,
                "support": 10365
            },
            "accuracy": 0.7241203467618562,
            "macro avg": {
                "precision": 0.7232130755896726,
                "recall": 0.7231707364797649,
                "f1-score": 0.7231914209699963,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7240951447848512,
                "recall": 0.7241203467618562,
                "f1-score": 0.7241072632999991,
                "support": 19610
            },
            "roc_auc": 0.8067385637847553,
            "score": 0.7241203467618562
        }
    }
}
