{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train1___4a3b9655842f4a8a8f6333a9bf1d7975.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8868261335237415,
                "recall": 0.9748822605965463,
                "f1-score": 0.928771733034212,
                "support": 5096
            },
            "1": {
                "precision": 0.8395989974937343,
                "recall": 0.5138036809815951,
                "f1-score": 0.6374881065651761,
                "support": 1304
            },
            "accuracy": 0.8809375,
            "macro avg": {
                "precision": 0.8632125655087379,
                "recall": 0.7443429707890707,
                "f1-score": 0.783129919799694,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8772036045576275,
                "recall": 0.8809375,
                "f1-score": 0.8694226941411459,
                "support": 6400
            },
            "roc_auc": 0.908618030742264,
            "score": 0.8809375
        },
        "val": {
            "0": {
                "precision": 0.8750882145377559,
                "recall": 0.9733124018838305,
                "f1-score": 0.9215904868078781,
                "support": 1274
            },
            "1": {
                "precision": 0.8142076502732241,
                "recall": 0.4570552147239264,
                "f1-score": 0.5854616895874264,
                "support": 326
            },
            "accuracy": 0.868125,
            "macro avg": {
                "precision": 0.84464793240549,
                "recall": 0.7151838083038784,
                "f1-score": 0.7535260881976522,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8626837995688575,
                "recall": 0.868125,
                "f1-score": 0.8531042443742111,
                "support": 1600
            },
            "roc_auc": 0.866812416330383,
            "score": 0.868125
        },
        "test": {
            "0": {
                "precision": 0.8692957746478873,
                "recall": 0.9686126804770873,
                "f1-score": 0.916270783847981,
                "support": 1593
            },
            "1": {
                "precision": 0.7777777777777778,
                "recall": 0.42997542997543,
                "f1-score": 0.5537974683544304,
                "support": 407
            },
            "accuracy": 0.859,
            "macro avg": {
                "precision": 0.8235367762128325,
                "recall": 0.6992940552262586,
                "f1-score": 0.7350341261012057,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8506718622848201,
                "recall": 0.859,
                "f1-score": 0.8425074641450434,
                "support": 2000
            },
            "roc_auc": 0.8535361247225655,
            "score": 0.859
        }
    }
}
