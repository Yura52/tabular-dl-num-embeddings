{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train3___29cb06878a7b47c7965aedacffadb92c.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7576675369886858,
                "recall": 0.7357176661483334,
                "f1-score": 0.7465312912686298,
                "support": 29582
            },
            "1": {
                "precision": 0.7702345265385293,
                "recall": 0.7901353673610901,
                "f1-score": 0.7800580400327406,
                "support": 33169
            },
            "accuracy": 0.7644818409268378,
            "macro avg": {
                "precision": 0.7639510317636076,
                "recall": 0.7629265167547118,
                "f1-score": 0.7632946656506852,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7643102116293888,
                "recall": 0.7644818409268378,
                "f1-score": 0.764252900960217,
                "support": 62751
            },
            "roc_auc": 0.8500486057272427,
            "score": 0.7644818409268378
        },
        "val": {
            "0": {
                "precision": 0.7361289402367708,
                "recall": 0.697809626825311,
                "f1-score": 0.7164572777122233,
                "support": 7396
            },
            "1": {
                "precision": 0.7424224962544659,
                "recall": 0.7768933912204534,
                "f1-score": 0.7592668984619012,
                "support": 8292
            },
            "accuracy": 0.7396098929117797,
            "macro avg": {
                "precision": 0.7392757182456183,
                "recall": 0.7373515090228822,
                "f1-score": 0.7378620880870623,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7394554424358227,
                "recall": 0.7396098929117797,
                "f1-score": 0.7390845963797609,
                "support": 15688
            },
            "roc_auc": 0.8215148923408621,
            "score": 0.7396098929117797
        },
        "test": {
            "0": {
                "precision": 0.7274571686203787,
                "recall": 0.6981070849107626,
                "f1-score": 0.7124799911685157,
                "support": 9245
            },
            "1": {
                "precision": 0.7400819519463587,
                "recall": 0.7667149059334298,
                "f1-score": 0.753163057385206,
                "support": 10365
            },
            "accuracy": 0.7343702192758796,
            "macro avg": {
                "precision": 0.7337695602833687,
                "recall": 0.7324109954220962,
                "f1-score": 0.7328215242768608,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7341300844375017,
                "recall": 0.7343702192758796,
                "f1-score": 0.7339833048521462,
                "support": 19610
            },
            "roc_auc": 0.8138313639763557,
            "score": 0.7343702192758796
        }
    }
}
