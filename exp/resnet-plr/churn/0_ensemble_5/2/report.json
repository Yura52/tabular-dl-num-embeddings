{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train3___5380b0e5f3ae4b00a3c25217e3447d97.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8801357627724187,
                "recall": 0.9668367346938775,
                "f1-score": 0.9214512810922011,
                "support": 5096
            },
            "1": {
                "precision": 0.7892768079800498,
                "recall": 0.4854294478527607,
                "f1-score": 0.6011396011396011,
                "support": 1304
            },
            "accuracy": 0.86875,
            "macro avg": {
                "precision": 0.8347062853762343,
                "recall": 0.7261330912733192,
                "f1-score": 0.7612954411159011,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8616232507334735,
                "recall": 0.86875,
                "f1-score": 0.8561877763018589,
                "support": 6400
            },
            "roc_auc": 0.8811784594677889,
            "score": 0.86875
        },
        "val": {
            "0": {
                "precision": 0.8797736916548797,
                "recall": 0.9764521193092621,
                "f1-score": 0.925595238095238,
                "support": 1274
            },
            "1": {
                "precision": 0.8387096774193549,
                "recall": 0.4785276073619632,
                "f1-score": 0.609375,
                "support": 326
            },
            "accuracy": 0.875,
            "macro avg": {
                "precision": 0.8592416845371174,
                "recall": 0.7274898633356126,
                "f1-score": 0.7674851190476191,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8714068987543917,
                "recall": 0.875,
                "f1-score": 0.8611653645833333,
                "support": 1600
            },
            "roc_auc": 0.8638990282285636,
            "score": 0.875
        },
        "test": {
            "0": {
                "precision": 0.8703494926719278,
                "recall": 0.9692404268675455,
                "f1-score": 0.9171369171369171,
                "support": 1593
            },
            "1": {
                "precision": 0.7831858407079646,
                "recall": 0.4348894348894349,
                "f1-score": 0.5592417061611376,
                "support": 407
            },
            "accuracy": 0.8605,
            "macro avg": {
                "precision": 0.8267676666899462,
                "recall": 0.7020649308784902,
                "f1-score": 0.7381893116490273,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8526116894972614,
                "recall": 0.8605,
                "f1-score": 0.8443052417033461,
                "support": 2000
            },
            "roc_auc": 0.8560764153984493,
            "score": 0.8605
        }
    }
}
