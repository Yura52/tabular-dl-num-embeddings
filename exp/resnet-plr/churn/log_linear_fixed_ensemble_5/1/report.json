{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train3___11d97c0d317c4c059685202cd0400fa4.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8930646332607117,
                "recall": 0.9652668759811617,
                "f1-score": 0.9277631082610336,
                "support": 5096
            },
            "1": {
                "precision": 0.8015695067264574,
                "recall": 0.5483128834355828,
                "f1-score": 0.651183970856102,
                "support": 1304
            },
            "accuracy": 0.8803125,
            "macro avg": {
                "precision": 0.8473170699935846,
                "recall": 0.7567898797083723,
                "f1-score": 0.7894735395585678,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8744225012293575,
                "recall": 0.8803125,
                "f1-score": 0.8714101090147787,
                "support": 6400
            },
            "roc_auc": 0.901657350646724,
            "score": 0.8803125
        },
        "val": {
            "0": {
                "precision": 0.8878437047756874,
                "recall": 0.9631083202511774,
                "f1-score": 0.9239457831325301,
                "support": 1274
            },
            "1": {
                "precision": 0.7844036697247706,
                "recall": 0.5245398773006135,
                "f1-score": 0.6286764705882352,
                "support": 326
            },
            "accuracy": 0.87375,
            "macro avg": {
                "precision": 0.836123687250229,
                "recall": 0.7438240987758955,
                "f1-score": 0.7763111268603826,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8667677976340632,
                "recall": 0.87375,
                "f1-score": 0.86378466070163,
                "support": 1600
            },
            "roc_auc": 0.8722154269919388,
            "score": 0.87375
        },
        "test": {
            "0": {
                "precision": 0.8790322580645161,
                "recall": 0.9579409918392969,
                "f1-score": 0.9167918293781917,
                "support": 1593
            },
            "1": {
                "precision": 0.7462121212121212,
                "recall": 0.48402948402948404,
                "f1-score": 0.587183308494784,
                "support": 407
            },
            "accuracy": 0.8615,
            "macro avg": {
                "precision": 0.8126221896383187,
                "recall": 0.7209852379343905,
                "f1-score": 0.7519875689364879,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8520033602150537,
                "recall": 0.8615,
                "f1-score": 0.8497164953784182,
                "support": 2000
            },
            "roc_auc": 0.8621132688929298,
            "score": 0.8615
        }
    }
}
