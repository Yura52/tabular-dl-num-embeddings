{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train3___370a7d3d084c4d7e83202c02830a807b.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8839541547277937,
                "recall": 0.9686028257456829,
                "f1-score": 0.9243445692883896,
                "support": 5096
            },
            "1": {
                "precision": 0.803921568627451,
                "recall": 0.5030674846625767,
                "f1-score": 0.6188679245283019,
                "support": 1304
            },
            "accuracy": 0.87375,
            "macro avg": {
                "precision": 0.8439378616776223,
                "recall": 0.7358351552041298,
                "f1-score": 0.7716062469083458,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8676475153098488,
                "recall": 0.87375,
                "f1-score": 0.8621037029185217,
                "support": 6400
            },
            "roc_auc": 0.9002674719014553,
            "score": 0.87375
        },
        "val": {
            "0": {
                "precision": 0.8805970149253731,
                "recall": 0.9725274725274725,
                "f1-score": 0.9242819843342037,
                "support": 1274
            },
            "1": {
                "precision": 0.8186528497409327,
                "recall": 0.48466257668711654,
                "f1-score": 0.6088631984585742,
                "support": 326
            },
            "accuracy": 0.873125,
            "macro avg": {
                "precision": 0.8496249323331528,
                "recall": 0.7285950246072945,
                "f1-score": 0.766572591396389,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8679758912690434,
                "recall": 0.873125,
                "f1-score": 0.8600154067120442,
                "support": 1600
            },
            "roc_auc": 0.8616044341285358,
            "score": 0.873125
        },
        "test": {
            "0": {
                "precision": 0.8726549175667994,
                "recall": 0.9635907093534212,
                "f1-score": 0.915871121718377,
                "support": 1593
            },
            "1": {
                "precision": 0.7593360995850622,
                "recall": 0.44963144963144963,
                "f1-score": 0.5648148148148149,
                "support": 407
            },
            "accuracy": 0.859,
            "macro avg": {
                "precision": 0.8159955085759307,
                "recall": 0.7066110794924354,
                "f1-score": 0.740342968266596,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8495945381075158,
                "recall": 0.859,
                "f1-score": 0.8444311632635021,
                "support": 2000
            },
            "roc_auc": 0.8546528038053461,
            "score": 0.859
        }
    }
}
