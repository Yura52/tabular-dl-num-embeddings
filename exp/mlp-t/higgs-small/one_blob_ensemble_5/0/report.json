{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train4___cbd69486d04b4da69d29ab342e233470.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.747650730502778,
                "recall": 0.7369346224055169,
                "f1-score": 0.7422540006809669,
                "support": 29582
            },
            "1": {
                "precision": 0.7683445956002739,
                "recall": 0.778166360155567,
                "f1-score": 0.7732242892663491,
                "support": 33169
            },
            "accuracy": 0.7587289445586525,
            "macro avg": {
                "precision": 0.7579976630515259,
                "recall": 0.757550491280542,
                "f1-score": 0.757739144973658,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7585891189176055,
                "recall": 0.7587289445586525,
                "f1-score": 0.7586243135379499,
                "support": 62751
            },
            "roc_auc": 0.8429562942724983,
            "score": 0.7587289445586525
        },
        "val": {
            "0": {
                "precision": 0.7281333898544581,
                "recall": 0.6967279610600324,
                "f1-score": 0.7120845712706418,
                "support": 7396
            },
            "1": {
                "precision": 0.7395192196028336,
                "recall": 0.7679691268692715,
                "f1-score": 0.7534757143702301,
                "support": 8292
            },
            "accuracy": 0.734382967873534,
            "macro avg": {
                "precision": 0.7338263047286459,
                "recall": 0.732348543964652,
                "f1-score": 0.7327801428204359,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.734151448260471,
                "recall": 0.734382967873534,
                "f1-score": 0.7339621438472472,
                "support": 15688
            },
            "roc_auc": 0.8132719848045005,
            "score": 0.734382967873534
        },
        "test": {
            "0": {
                "precision": 0.7174536628420124,
                "recall": 0.7034072471606274,
                "f1-score": 0.7103610246326943,
                "support": 9245
            },
            "1": {
                "precision": 0.7399962070927366,
                "recall": 0.7529184756391702,
                "f1-score": 0.7464014155229306,
                "support": 10365
            },
            "accuracy": 0.7295767465578786,
            "macro avg": {
                "precision": 0.7287249349673746,
                "recall": 0.7281628613998988,
                "f1-score": 0.7283812200778125,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7293686792193076,
                "recall": 0.7295767465578786,
                "f1-score": 0.7294104204295989,
                "support": 19610
            },
            "roc_auc": 0.8073466342219116,
            "score": 0.7295767465578786
        }
    }
}
