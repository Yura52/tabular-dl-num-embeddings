{
    "program": "bin/train1___dbd28d247ea74f77a5055f0c27af10bc.py",
    "environment": {
        "CUDA_VISIBLE_DEVICES": "1",
        "gpus": {
            "driver": "460.106.00",
            "devices": [
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11554717696,
                    "memory_free": 11550654464,
                    "memory_used": 4063232,
                    "utilization": 12
                },
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11552096256,
                    "memory_free": 11548033024,
                    "memory_used": 4063232,
                    "utilization": 4
                }
            ]
        },
        "torch.version.cuda": "11.1",
        "torch.backends.cudnn.version()": 8005,
        "torch.cuda.nccl.version()": [
            2,
            10,
            3
        ]
    },
    "config": {
        "seed": 9,
        "data": {
            "path": "data/eye",
            "T": {
                "seed": 0,
                "normalization": "standard",
                "num_nan_policy": null,
                "cat_nan_policy": null,
                "cat_min_frequency": null,
                "cat_encoding": null,
                "y_policy": "default"
            },
            "T_cache": true
        },
        "model": {
            "d_num_embedding": null,
            "num_embedding_arch": [],
            "d_cat_embedding": null,
            "mlp": {
                "d_layers": [
                    941,
                    389,
                    389,
                    662
                ],
                "dropout": 0.3245665807709869
            },
            "resnet": null,
            "transformer": null,
            "transformer_default": false,
            "transformer_baseline": true,
            "memory_efficient": true
        },
        "training": {
            "batch_size": 128,
            "lr": 0.0003096724873720203,
            "weight_decay": 6.822858398996003e-05,
            "optimizer": "AdamW",
            "patience": 16,
            "n_epochs": Infinity,
            "eval_batch_size": 8192
        },
        "bins": {
            "count": 23,
            "value": "one",
            "tree": {
                "min_samples_leaf": 30,
                "min_impurity_decrease": 0.00029986682562702023
            },
            "subsample": null
        }
    },
    "prediction_type": "logits",
    "epoch_size": 55,
    "n_parameters": 1341976,
    "best_epoch": 70,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9821048146570089,
                "recall": 0.947000821692687,
                "f1-score": 0.9642334239698808,
                "support": 2434
            },
            "1": {
                "precision": 0.9554367201426025,
                "recall": 0.9827649431609827,
                "f1-score": 0.9689081706435285,
                "support": 2727
            },
            "2": {
                "precision": 0.9907908992416035,
                "recall": 0.9956450734893849,
                "f1-score": 0.9932120553896281,
                "support": 1837
            },
            "accuracy": 0.9737067733638183,
            "macro avg": {
                "precision": 0.9761108113470716,
                "recall": 0.9751369461143516,
                "f1-score": 0.9754512166676791,
                "support": 6998
            },
            "weighted avg": {
                "precision": 0.9739928460432783,
                "recall": 0.9737067733638183,
                "f1-score": 0.9736620864587509,
                "support": 6998
            },
            "score": 0.9737067733638183
        },
        "val": {
            "0": {
                "precision": 0.6288998357963875,
                "recall": 0.6288998357963875,
                "f1-score": 0.6288998357963875,
                "support": 609
            },
            "1": {
                "precision": 0.6288515406162465,
                "recall": 0.658357771260997,
                "f1-score": 0.6432664756446992,
                "support": 682
            },
            "2": {
                "precision": 0.7634660421545667,
                "recall": 0.710239651416122,
                "f1-score": 0.7358916478555305,
                "support": 459
            },
            "accuracy": 0.6617142857142857,
            "macro avg": {
                "precision": 0.6737391395224002,
                "recall": 0.6658324194911689,
                "f1-score": 0.6693526530988724,
                "support": 1750
            },
            "weighted avg": {
                "precision": 0.6641758080281294,
                "recall": 0.6617142857142857,
                "f1-score": 0.6625611444316418,
                "support": 1750
            },
            "score": 0.6617142857142857
        },
        "test": {
            "0": {
                "precision": 0.6320474777448071,
                "recall": 0.5597897503285151,
                "f1-score": 0.5937282229965157,
                "support": 761
            },
            "1": {
                "precision": 0.5995670995670995,
                "recall": 0.64947245017585,
                "f1-score": 0.6235227912211592,
                "support": 853
            },
            "2": {
                "precision": 0.7033898305084746,
                "recall": 0.7229965156794426,
                "f1-score": 0.7130584192439863,
                "support": 574
            },
            "accuracy": 0.6375685557586838,
            "macro avg": {
                "precision": 0.6450014692734604,
                "recall": 0.6440862387279358,
                "f1-score": 0.6434364778205537,
                "support": 2188
            },
            "weighted avg": {
                "precision": 0.6381008360175496,
                "recall": 0.6375685557586838,
                "f1-score": 0.6366488351270774,
                "support": 2188
            },
            "score": 0.6375685557586838
        }
    },
    "time": "0:00:13"
}
