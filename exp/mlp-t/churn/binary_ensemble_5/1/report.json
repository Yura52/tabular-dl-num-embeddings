{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train1___70d787141d914478b48d2c27f3a74662.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8865107913669065,
                "recall": 0.9672291993720565,
                "f1-score": 0.9251126126126127,
                "support": 5096
            },
            "1": {
                "precision": 0.8011904761904762,
                "recall": 0.5161042944785276,
                "f1-score": 0.6277985074626866,
                "support": 1304
            },
            "accuracy": 0.8753125,
            "macro avg": {
                "precision": 0.8438506337786913,
                "recall": 0.741666746925292,
                "f1-score": 0.7764555600376497,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8691267771497089,
                "recall": 0.8753125,
                "f1-score": 0.8645348636883152,
                "support": 6400
            },
            "roc_auc": 0.8956621818146796,
            "score": 0.8753125
        },
        "val": {
            "0": {
                "precision": 0.8783592644978784,
                "recall": 0.9748822605965463,
                "f1-score": 0.9241071428571429,
                "support": 1274
            },
            "1": {
                "precision": 0.8279569892473119,
                "recall": 0.4723926380368098,
                "f1-score": 0.6015625,
                "support": 326
            },
            "accuracy": 0.8725,
            "macro avg": {
                "precision": 0.8531581268725952,
                "recall": 0.7236374493166781,
                "f1-score": 0.7628348214285714,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8680898009155754,
                "recall": 0.8725,
                "f1-score": 0.858388671875,
                "support": 1600
            },
            "roc_auc": 0.8673674047249857,
            "score": 0.8725
        },
        "test": {
            "0": {
                "precision": 0.8707289293849658,
                "recall": 0.9598242310106717,
                "f1-score": 0.9131083905643476,
                "support": 1593
            },
            "1": {
                "precision": 0.7377049180327869,
                "recall": 0.44226044226044225,
                "f1-score": 0.5529953917050691,
                "support": 407
            },
            "accuracy": 0.8545,
            "macro avg": {
                "precision": 0.8042169237088763,
                "recall": 0.7010423366355569,
                "f1-score": 0.7330518911347084,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8436585430747974,
                "recall": 0.8545,
                "f1-score": 0.8398253952964845,
                "support": 2000
            },
            "roc_auc": 0.8550538211555161,
            "score": 0.8545
        }
    }
}
