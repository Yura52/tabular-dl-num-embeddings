{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train1___70d787141d914478b48d2c27f3a74662.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8889486903480445,
                "recall": 0.972331240188383,
                "f1-score": 0.9287722586691658,
                "support": 5096
            },
            "1": {
                "precision": 0.8292978208232445,
                "recall": 0.5253067484662577,
                "f1-score": 0.6431924882629108,
                "support": 1304
            },
            "accuracy": 0.88125,
            "macro avg": {
                "precision": 0.8591232555856445,
                "recall": 0.7488189943273204,
                "f1-score": 0.7859823734660383,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8767948256823663,
                "recall": 0.88125,
                "f1-score": 0.8705853804488913,
                "support": 6400
            },
            "roc_auc": 0.9045049768373608,
            "score": 0.88125
        },
        "val": {
            "0": {
                "precision": 0.8786167960479887,
                "recall": 0.9772370486656201,
                "f1-score": 0.9253065774804906,
                "support": 1274
            },
            "1": {
                "precision": 0.8415300546448088,
                "recall": 0.4723926380368098,
                "f1-score": 0.6051080550098232,
                "support": 326
            },
            "accuracy": 0.874375,
            "macro avg": {
                "precision": 0.8600734253463987,
                "recall": 0.7248148433512149,
                "f1-score": 0.7652073162451569,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8710603724870909,
                "recall": 0.874375,
                "f1-score": 0.8600661285270921,
                "support": 1600
            },
            "roc_auc": 0.8672373857518467,
            "score": 0.874375
        },
        "test": {
            "0": {
                "precision": 0.8699602498580352,
                "recall": 0.9617074701820465,
                "f1-score": 0.913536076326774,
                "support": 1593
            },
            "1": {
                "precision": 0.7447698744769874,
                "recall": 0.43734643734643736,
                "f1-score": 0.5510835913312693,
                "support": 407
            },
            "accuracy": 0.855,
            "macro avg": {
                "precision": 0.8073650621675112,
                "recall": 0.6995269537642419,
                "f1-score": 0.7323098338290217,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.844484008467992,
                "recall": 0.855,
                "f1-score": 0.8397769956301888,
                "support": 2000
            },
            "roc_auc": 0.856175127361568,
            "score": 0.855
        }
    }
}
