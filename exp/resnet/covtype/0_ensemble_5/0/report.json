{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train0___2e9c31e8ce324fb9b5acc0aa58132d66.py",
    "data": "data/covtype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.98845107192637,
                "recall": 0.9885895941819469,
                "f1-score": 0.9885203282013459,
                "support": 135578
            },
            "1": {
                "precision": 0.9917241226907098,
                "recall": 0.9900613307447935,
                "f1-score": 0.9908920291455067,
                "support": 181312
            },
            "2": {
                "precision": 0.9962761762901954,
                "recall": 0.9938379512280395,
                "f1-score": 0.9950555701408944,
                "support": 22882
            },
            "3": {
                "precision": 0.9864330130016958,
                "recall": 0.992040932347925,
                "f1-score": 0.9892290249433106,
                "support": 1759
            },
            "4": {
                "precision": 0.9526844033774096,
                "recall": 0.9843621399176955,
                "f1-score": 0.9682642487046632,
                "support": 6075
            },
            "5": {
                "precision": 0.9873259550160657,
                "recall": 0.9952316689158794,
                "f1-score": 0.9912630494197768,
                "support": 11115
            },
            "6": {
                "precision": 0.9850372170742823,
                "recall": 0.9880390065518818,
                "f1-score": 0.9865358283888636,
                "support": 13126
            },
            "accuracy": 0.9897565396520612,
            "macro avg": {
                "precision": 0.9839902799109612,
                "recall": 0.9903089462697375,
                "f1-score": 0.9871085827063373,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.9897805144333879,
                "recall": 0.9897565396520612,
                "f1-score": 0.9897632721112858,
                "support": 371847
            },
            "score": 0.9897565396520612
        },
        "val": {
            "0": {
                "precision": 0.9670050761421319,
                "recall": 0.9667197734112232,
                "f1-score": 0.9668624037298238,
                "support": 33894
            },
            "1": {
                "precision": 0.9741451762728358,
                "recall": 0.9716951994352276,
                "f1-score": 0.9729186454904907,
                "support": 45328
            },
            "2": {
                "precision": 0.9727129613433619,
                "recall": 0.9720328613878693,
                "f1-score": 0.9723727924462318,
                "support": 5721
            },
            "3": {
                "precision": 0.9216589861751152,
                "recall": 0.9111617312072893,
                "f1-score": 0.9163802978235968,
                "support": 439
            },
            "4": {
                "precision": 0.8757881462799496,
                "recall": 0.9144173798551679,
                "f1-score": 0.8946859903381643,
                "support": 1519
            },
            "5": {
                "precision": 0.9443262411347517,
                "recall": 0.9582583663188197,
                "f1-score": 0.9512412930880514,
                "support": 2779
            },
            "6": {
                "precision": 0.9600846688841851,
                "recall": 0.9673979280926265,
                "f1-score": 0.9637274244953711,
                "support": 3282
            },
            "accuracy": 0.9681267614724296,
            "macro avg": {
                "precision": 0.9451030366046188,
                "recall": 0.951669034244032,
                "f1-score": 0.9483126924873899,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9682109297263763,
                "recall": 0.9681267614724296,
                "f1-score": 0.9681591117999853,
                "support": 92962
            },
            "score": 0.9681267614724296
        },
        "test": {
            "0": {
                "precision": 0.9681210831264042,
                "recall": 0.9662245090634441,
                "f1-score": 0.9671718663248793,
                "support": 42368
            },
            "1": {
                "precision": 0.9731505687840034,
                "recall": 0.9723089956054429,
                "f1-score": 0.972729600169502,
                "support": 56661
            },
            "2": {
                "precision": 0.9682451253481894,
                "recall": 0.9721717242343728,
                "f1-score": 0.9702044518875166,
                "support": 7151
            },
            "3": {
                "precision": 0.9163568773234201,
                "recall": 0.8979963570127505,
                "f1-score": 0.9070837166513339,
                "support": 549
            },
            "4": {
                "precision": 0.8809034907597536,
                "recall": 0.9036334913112164,
                "f1-score": 0.8921237327787886,
                "support": 1899
            },
            "5": {
                "precision": 0.9436379163108455,
                "recall": 0.9545061906133027,
                "f1-score": 0.949040939020899,
                "support": 3473
            },
            "6": {
                "precision": 0.9638962927065665,
                "recall": 0.96977084349098,
                "f1-score": 0.966824644549763,
                "support": 4102
            },
            "accuracy": 0.9679870571327762,
            "macro avg": {
                "precision": 0.9449016220513118,
                "recall": 0.9480874444759299,
                "f1-score": 0.9464541359118118,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9680303610902304,
                "recall": 0.9679870571327762,
                "f1-score": 0.9680039873777397,
                "support": 116203
            },
            "score": 0.9679870571327762
        }
    }
}
