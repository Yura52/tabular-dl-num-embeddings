{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train0___f1fd8985f7224ae598504f7844ba649a.py",
    "data": "data/covtype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9923459964241914,
                "recall": 0.9907064567997758,
                "f1-score": 0.9915255488462049,
                "support": 135578
            },
            "1": {
                "precision": 0.993007070078085,
                "recall": 0.9938669255206495,
                "f1-score": 0.9934368117404163,
                "support": 181312
            },
            "2": {
                "precision": 0.9967580828879348,
                "recall": 0.9943186784371996,
                "f1-score": 0.9955368863218693,
                "support": 22882
            },
            "3": {
                "precision": 0.9814502529510961,
                "recall": 0.992609437180216,
                "f1-score": 0.9869983041266253,
                "support": 1759
            },
            "4": {
                "precision": 0.9790980908492429,
                "recall": 0.9792592592592593,
                "f1-score": 0.9791786684223521,
                "support": 6075
            },
            "5": {
                "precision": 0.9907747424988804,
                "recall": 0.9952316689158794,
                "f1-score": 0.9929982046678636,
                "support": 11115
            },
            "6": {
                "precision": 0.986644407345576,
                "recall": 0.9905531007161359,
                "f1-score": 0.988594890510949,
                "support": 13126
            },
            "accuracy": 0.9924216142660826,
            "macro avg": {
                "precision": 0.9885826632907152,
                "recall": 0.9909350752613023,
                "f1-score": 0.9897527592337545,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.9924236298703006,
                "recall": 0.9924216142660826,
                "f1-score": 0.99242175709343,
                "support": 371847
            },
            "score": 0.9924216142660826
        },
        "val": {
            "0": {
                "precision": 0.9680766161213089,
                "recall": 0.9662772172065852,
                "f1-score": 0.9671760797342194,
                "support": 33894
            },
            "1": {
                "precision": 0.9731034634802355,
                "recall": 0.9737689728203318,
                "f1-score": 0.9734361044030568,
                "support": 45328
            },
            "2": {
                "precision": 0.9731004366812227,
                "recall": 0.9737808075511274,
                "f1-score": 0.9734405032325703,
                "support": 5721
            },
            "3": {
                "precision": 0.920814479638009,
                "recall": 0.9271070615034168,
                "f1-score": 0.9239500567536889,
                "support": 439
            },
            "4": {
                "precision": 0.9096385542168675,
                "recall": 0.8946675444371297,
                "f1-score": 0.9020909392631928,
                "support": 1519
            },
            "5": {
                "precision": 0.9482512491077801,
                "recall": 0.9560993163008277,
                "f1-score": 0.9521591112703816,
                "support": 2779
            },
            "6": {
                "precision": 0.9628286491387126,
                "recall": 0.9707495429616088,
                "f1-score": 0.9667728720983159,
                "support": 3282
            },
            "accuracy": 0.9688905144037349,
            "macro avg": {
                "precision": 0.950830492626305,
                "recall": 0.9517786375401467,
                "f1-score": 0.9512893809650608,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9688808608448753,
                "recall": 0.9688905144037349,
                "f1-score": 0.9688831980162825,
                "support": 92962
            },
            "score": 0.9688905144037349
        },
        "test": {
            "0": {
                "precision": 0.9700144594306302,
                "recall": 0.9658704682779456,
                "f1-score": 0.9679380285021584,
                "support": 42368
            },
            "1": {
                "precision": 0.9718314818401085,
                "recall": 0.974232717389386,
                "f1-score": 0.9730306181805362,
                "support": 56661
            },
            "2": {
                "precision": 0.9688851681317148,
                "recall": 0.9710529995804783,
                "f1-score": 0.9699678726079061,
                "support": 7151
            },
            "3": {
                "precision": 0.906934306569343,
                "recall": 0.9052823315118397,
                "f1-score": 0.9061075660893345,
                "support": 549
            },
            "4": {
                "precision": 0.9007551240560949,
                "recall": 0.8794102159031069,
                "f1-score": 0.8899547029043431,
                "support": 1899
            },
            "5": {
                "precision": 0.9441900400686892,
                "recall": 0.9498992225741434,
                "f1-score": 0.947036026984355,
                "support": 3473
            },
            "6": {
                "precision": 0.9636319845857418,
                "recall": 0.9753778644563628,
                "f1-score": 0.9694693481948147,
                "support": 4102
            },
            "accuracy": 0.9684259442527301,
            "macro avg": {
                "precision": 0.9466060806689033,
                "recall": 0.9458751170990375,
                "f1-score": 0.9462148804947782,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9684039600683939,
                "recall": 0.9684259442527301,
                "f1-score": 0.9684089303024547,
                "support": 116203
            },
            "score": 0.9684259442527301
        }
    }
}
