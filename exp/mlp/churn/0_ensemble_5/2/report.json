{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train0___fda5e588a5a047ce8eabc3c6cae6f47c.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8861700199383723,
                "recall": 0.9593799058084772,
                "f1-score": 0.9213229058701592,
                "support": 5096
            },
            "1": {
                "precision": 0.7655719139297849,
                "recall": 0.5184049079754601,
                "f1-score": 0.6181984453589392,
                "support": 1304
            },
            "accuracy": 0.86953125,
            "macro avg": {
                "precision": 0.8258709669340786,
                "recall": 0.7388924068919687,
                "f1-score": 0.7697606756145492,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8615981558391226,
                "recall": 0.86953125,
                "f1-score": 0.8595612970409983,
                "support": 6400
            },
            "roc_auc": 0.8873712150032265,
            "score": 0.86953125
        },
        "val": {
            "0": {
                "precision": 0.8854242204496011,
                "recall": 0.9583987441130298,
                "f1-score": 0.9204673954014323,
                "support": 1274
            },
            "1": {
                "precision": 0.7601809954751131,
                "recall": 0.5153374233128835,
                "f1-score": 0.6142595978062156,
                "support": 326
            },
            "accuracy": 0.868125,
            "macro avg": {
                "precision": 0.8228026079623572,
                "recall": 0.7368680837129566,
                "f1-score": 0.767363496603824,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8599059133610492,
                "recall": 0.868125,
                "f1-score": 0.8580775566414068,
                "support": 1600
            },
            "roc_auc": 0.8617633462068168,
            "score": 0.868125
        },
        "test": {
            "0": {
                "precision": 0.8751438434982739,
                "recall": 0.9548022598870056,
                "f1-score": 0.913239267487241,
                "support": 1593
            },
            "1": {
                "precision": 0.7251908396946565,
                "recall": 0.4668304668304668,
                "f1-score": 0.5680119581464872,
                "support": 407
            },
            "accuracy": 0.8555,
            "macro avg": {
                "precision": 0.8001673415964652,
                "recall": 0.7108163633587362,
                "f1-score": 0.7406256128168641,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8446284072242378,
                "recall": 0.8555,
                "f1-score": 0.8429855100363977,
                "support": 2000
            },
            "roc_auc": 0.8524163608909373,
            "score": 0.8555
        }
    }
}
