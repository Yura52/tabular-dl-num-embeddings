{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train1___880364900bf2480b8a18a65a49bc7543.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7403117594045195,
                "recall": 0.7497464674464202,
                "f1-score": 0.7449992442182698,
                "support": 29582
            },
            "1": {
                "precision": 0.7742437179799951,
                "recall": 0.7654436371310561,
                "f1-score": 0.7698185291308501,
                "support": 33169
            },
            "accuracy": 0.7580436965147965,
            "macro avg": {
                "precision": 0.7572777386922573,
                "recall": 0.7575950522887381,
                "f1-score": 0.75740888667456,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7582475553916743,
                "recall": 0.7580436965147965,
                "f1-score": 0.7581182520630113,
                "support": 62751
            },
            "roc_auc": 0.8416827010437096,
            "score": 0.7580436965147965
        },
        "val": {
            "0": {
                "precision": 0.7200709026452141,
                "recall": 0.7140346133044889,
                "f1-score": 0.7170400543109301,
                "support": 7396
            },
            "1": {
                "precision": 0.7468278668901125,
                "recall": 0.7524119633381573,
                "f1-score": 0.7496095157995915,
                "support": 8292
            },
            "accuracy": 0.7343192248852626,
            "macro avg": {
                "precision": 0.7334493847676633,
                "recall": 0.7332232883213231,
                "f1-score": 0.7333247850552608,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7342134796160643,
                "recall": 0.7343192248852626,
                "f1-score": 0.7342548665664108,
                "support": 15688
            },
            "roc_auc": 0.8138198047496763,
            "score": 0.7343192248852626
        },
        "test": {
            "0": {
                "precision": 0.7081632653061225,
                "recall": 0.7131422390481341,
                "f1-score": 0.710644031258421,
                "support": 9245
            },
            "1": {
                "precision": 0.7425242718446602,
                "recall": 0.737867824409069,
                "f1-score": 0.7401887248971691,
                "support": 10365
            },
            "accuracy": 0.7262111167771546,
            "macro avg": {
                "precision": 0.7253437685753914,
                "recall": 0.7255050317286016,
                "f1-score": 0.7254163780777951,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7263250109854669,
                "recall": 0.7262111167771546,
                "f1-score": 0.7262600817207171,
                "support": 19610
            },
            "roc_auc": 0.8061626459016059,
            "score": 0.7262111167771546
        }
    }
}
