{
    "program": "bin/train1___6ab213dee2d74dac9c3295d3cd6416c4.py",
    "environment": {
        "CUDA_VISIBLE_DEVICES": "1",
        "gpus": {
            "driver": "460.106.00",
            "devices": [
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11554717696,
                    "memory_free": 11550654464,
                    "memory_used": 4063232,
                    "utilization": 19
                },
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11552096256,
                    "memory_free": 11548033024,
                    "memory_used": 4063232,
                    "utilization": 16
                }
            ]
        },
        "torch.version.cuda": "11.1",
        "torch.backends.cudnn.version()": 8005,
        "torch.cuda.nccl.version()": [
            2,
            10,
            3
        ]
    },
    "config": {
        "seed": 11,
        "data": {
            "path": "data/eye",
            "T": {
                "seed": 0,
                "normalization": "standard",
                "num_nan_policy": null,
                "cat_nan_policy": null,
                "cat_min_frequency": null,
                "cat_encoding": null,
                "y_policy": "default"
            },
            "T_cache": true
        },
        "model": {
            "d_num_embedding": 121,
            "num_embedding_arch": [
                "linear",
                "relu",
                "linear",
                "relu"
            ],
            "d_cat_embedding": null,
            "mlp": {
                "d_layers": [
                    506,
                    568
                ],
                "dropout": 0.4107242677005108
            },
            "resnet": null,
            "transformer": null,
            "transformer_default": false,
            "transformer_baseline": true,
            "memory_efficient": false
        },
        "training": {
            "batch_size": 128,
            "lr": 0.0010657385580277914,
            "weight_decay": 0.0,
            "optimizer": "AdamW",
            "patience": 16,
            "n_epochs": Infinity,
            "eval_batch_size": 8192
        },
        "bins": {
            "count": 243,
            "tree": {
                "min_samples_leaf": 25,
                "min_impurity_decrease": 0.003837061483960133
            },
            "subsample": null
        }
    },
    "prediction_type": "logits",
    "epoch_size": 55,
    "n_parameters": 2281607,
    "best_epoch": 86,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.879133409350057,
                "recall": 0.9502875924404273,
                "f1-score": 0.9133267522211255,
                "support": 2434
            },
            "1": {
                "precision": 0.9483642096964919,
                "recall": 0.8822882288228823,
                "f1-score": 0.9141337386018237,
                "support": 2727
            },
            "2": {
                "precision": 0.9836065573770492,
                "recall": 0.979858464888405,
                "f1-score": 0.981728933733297,
                "support": 1837
            },
            "accuracy": 0.9315518719634182,
            "macro avg": {
                "precision": 0.9370347254745326,
                "recall": 0.9374780953839048,
                "f1-score": 0.936396474852082,
                "support": 6998
            },
            "weighted avg": {
                "precision": 0.9335360337384984,
                "recall": 0.9315518719634182,
                "f1-score": 0.9315970379167562,
                "support": 6998
            },
            "score": 0.9315518719634182
        },
        "val": {
            "0": {
                "precision": 0.6869436201780416,
                "recall": 0.7602627257799671,
                "f1-score": 0.7217459080280593,
                "support": 609
            },
            "1": {
                "precision": 0.7488,
                "recall": 0.6862170087976539,
                "f1-score": 0.7161438408569242,
                "support": 682
            },
            "2": {
                "precision": 0.8381374722838137,
                "recall": 0.8235294117647058,
                "f1-score": 0.8307692307692307,
                "support": 459
            },
            "accuracy": 0.748,
            "macro avg": {
                "precision": 0.7579603641539517,
                "recall": 0.7566697154474422,
                "f1-score": 0.756219659884738,
                "support": 1750
            },
            "weighted avg": {
                "precision": 0.7507059225523988,
                "recall": 0.748,
                "f1-score": 0.7481579625009069,
                "support": 1750
            },
            "score": 0.748
        },
        "test": {
            "0": {
                "precision": 0.6859605911330049,
                "recall": 0.7319316688567674,
                "f1-score": 0.7082008900190717,
                "support": 761
            },
            "1": {
                "precision": 0.7464968152866241,
                "recall": 0.6869871043376319,
                "f1-score": 0.7155067155067154,
                "support": 853
            },
            "2": {
                "precision": 0.8138747884940778,
                "recall": 0.837979094076655,
                "f1-score": 0.8257510729613733,
                "support": 574
            },
            "accuracy": 0.7422303473491774,
            "macro avg": {
                "precision": 0.7487773983045689,
                "recall": 0.7522992890903515,
                "f1-score": 0.7498195594957201,
                "support": 2188
            },
            "weighted avg": {
                "precision": 0.7431178802044368,
                "recall": 0.7422303473491774,
                "f1-score": 0.7418872127566593,
                "support": 2188
            },
            "score": 0.7422303473491774
        }
    },
    "eval_batch_size": 4096,
    "time": "0:00:29"
}
