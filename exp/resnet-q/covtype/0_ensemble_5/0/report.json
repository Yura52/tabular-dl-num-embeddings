{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train1___8e55c53692294c8c8915b1110a787635.py",
    "data": "data/covtype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9996459550362896,
                "recall": 0.9996312086031657,
                "f1-score": 0.9996385817653437,
                "support": 135578
            },
            "1": {
                "precision": 0.9997297267482267,
                "recall": 0.9996525326509001,
                "f1-score": 0.999691128209371,
                "support": 181312
            },
            "2": {
                "precision": 0.9999562822418466,
                "recall": 0.99960667773796,
                "f1-score": 0.9997814494273974,
                "support": 22882
            },
            "3": {
                "precision": 0.9994311717861206,
                "recall": 0.9988629903354178,
                "f1-score": 0.9991470002843332,
                "support": 1759
            },
            "4": {
                "precision": 0.9972080801445229,
                "recall": 0.9995061728395062,
                "f1-score": 0.9983558040118382,
                "support": 6075
            },
            "5": {
                "precision": 0.9993705602014208,
                "recall": 0.9999100314889788,
                "f1-score": 0.9996402230617017,
                "support": 11115
            },
            "6": {
                "precision": 0.9987815094052243,
                "recall": 0.9991619686119153,
                "f1-score": 0.9989717027840196,
                "support": 13126
            },
            "accuracy": 0.9996261903417266,
            "macro avg": {
                "precision": 0.9991604693662358,
                "recall": 0.9994759403239778,
                "f1-score": 0.9993179842205722,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.9996263074476437,
                "recall": 0.9996261903417266,
                "f1-score": 0.9996262208252934,
                "support": 371847
            },
            "score": 0.9996261903417266
        },
        "val": {
            "0": {
                "precision": 0.9756522252390509,
                "recall": 0.975364371275152,
                "f1-score": 0.9755082770220425,
                "support": 33894
            },
            "1": {
                "precision": 0.9800499304067339,
                "recall": 0.9786445464172255,
                "f1-score": 0.9793467342230464,
                "support": 45328
            },
            "2": {
                "precision": 0.976148719747457,
                "recall": 0.9729068344694983,
                "f1-score": 0.9745250809769762,
                "support": 5721
            },
            "3": {
                "precision": 0.9172413793103448,
                "recall": 0.908883826879271,
                "f1-score": 0.9130434782608695,
                "support": 439
            },
            "4": {
                "precision": 0.9080906148867314,
                "recall": 0.923633969716919,
                "f1-score": 0.9157963446475196,
                "support": 1519
            },
            "5": {
                "precision": 0.9478353442157559,
                "recall": 0.9611370996761425,
                "f1-score": 0.9544398785063427,
                "support": 2779
            },
            "6": {
                "precision": 0.9668174962292609,
                "recall": 0.9765386959171237,
                "f1-score": 0.9716537820221313,
                "support": 3282
            },
            "accuracy": 0.9752694649426648,
            "macro avg": {
                "precision": 0.953119387147905,
                "recall": 0.9567299063359046,
                "f1-score": 0.954901939379847,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.975303830028767,
                "recall": 0.9752694649426648,
                "f1-score": 0.9752828162900811,
                "support": 92962
            },
            "score": 0.9752694649426648
        },
        "test": {
            "0": {
                "precision": 0.975398590149974,
                "recall": 0.9732345166163142,
                "f1-score": 0.9743153517166419,
                "support": 42368
            },
            "1": {
                "precision": 0.9780008467998024,
                "recall": 0.9783978397839784,
                "f1-score": 0.9781993030129251,
                "support": 56661
            },
            "2": {
                "precision": 0.9727805695142379,
                "recall": 0.9745490141238987,
                "f1-score": 0.9736639888229129,
                "support": 7151
            },
            "3": {
                "precision": 0.9309701492537313,
                "recall": 0.9089253187613844,
                "f1-score": 0.919815668202765,
                "support": 549
            },
            "4": {
                "precision": 0.9105098855359001,
                "recall": 0.9215376513954713,
                "f1-score": 0.9159905783826223,
                "support": 1899
            },
            "5": {
                "precision": 0.9522584333905089,
                "recall": 0.9591131586524618,
                "f1-score": 0.9556735045187205,
                "support": 3473
            },
            "6": {
                "precision": 0.9706666666666667,
                "recall": 0.9761092150170648,
                "f1-score": 0.9733803330497143,
                "support": 4102
            },
            "accuracy": 0.9743638288168119,
            "macro avg": {
                "precision": 0.9557978773301173,
                "recall": 0.9559809591929392,
                "f1-score": 0.9558626753866146,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9743773946541732,
                "recall": 0.9743638288168119,
                "f1-score": 0.9743683022914559,
                "support": 116203
            },
            "score": 0.9743638288168119
        }
    }
}
