{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train0___440adc4687a246f0bb56d31dad7de399.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7700691030357204,
                "recall": 0.7571834223514299,
                "f1-score": 0.7635719033902061,
                "support": 29582
            },
            "1": {
                "precision": 0.7866266634980988,
                "recall": 0.7983659441044348,
                "f1-score": 0.7924528301886792,
                "support": 33169
            },
            "accuracy": 0.7789517298529107,
            "macro avg": {
                "precision": 0.7783478832669096,
                "recall": 0.7777746832279324,
                "f1-score": 0.7780123667894426,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7788211185092049,
                "recall": 0.7789517298529107,
                "f1-score": 0.7788378188493789,
                "support": 62751
            },
            "roc_auc": 0.8652545719180633,
            "score": 0.7789517298529107
        },
        "val": {
            "0": {
                "precision": 0.734159391720642,
                "recall": 0.7049756625202812,
                "f1-score": 0.7192716236722306,
                "support": 7396
            },
            "1": {
                "precision": 0.7458653622175635,
                "recall": 0.7723106608779546,
                "f1-score": 0.758857684559782,
                "support": 8292
            },
            "accuracy": 0.7405660377358491,
            "macro avg": {
                "precision": 0.7400123769691027,
                "recall": 0.7386431616991179,
                "f1-score": 0.7390646541160063,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7403466627150628,
                "recall": 0.7405660377358491,
                "f1-score": 0.7401951076650644,
                "support": 15688
            },
            "roc_auc": 0.8213057370289464,
            "score": 0.7405660377358491
        },
        "test": {
            "0": {
                "precision": 0.7230187840391241,
                "recall": 0.7036235803136831,
                "f1-score": 0.7131893432737638,
                "support": 9245
            },
            "1": {
                "precision": 0.7418260623763309,
                "recall": 0.7595754944524843,
                "f1-score": 0.7505958623319668,
                "support": 10365
            },
            "accuracy": 0.7331973482916879,
            "macro avg": {
                "precision": 0.7324224232077274,
                "recall": 0.7315995373830837,
                "f1-score": 0.7318926028028654,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7329594999985911,
                "recall": 0.7331973482916879,
                "f1-score": 0.7329608154837727,
                "support": 19610
            },
            "roc_auc": 0.8132941053390093,
            "score": 0.7331973482916879
        }
    }
}
