{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train1___ae3e4b478e7b4c04945e25b09f157311.py",
    "data": "data/adult",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8955058880076905,
                "recall": 0.9421491782553729,
                "f1-score": 0.9182355840315427,
                "support": 19775
            },
            "1": {
                "precision": 0.7818043105092505,
                "recall": 0.6534353578829906,
                "f1-score": 0.7118791246960751,
                "support": 6273
            },
            "accuracy": 0.8726197788697788,
            "macro avg": {
                "precision": 0.8386550992584705,
                "recall": 0.7977922680691818,
                "f1-score": 0.8150573543638089,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.868123747511387,
                "recall": 0.8726197788697788,
                "f1-score": 0.8685398657648279,
                "support": 26048
            },
            "roc_auc": 0.9308595080596451,
            "score": 0.8726197788697788
        },
        "val": {
            "0": {
                "precision": 0.8882896764252697,
                "recall": 0.9326592517694641,
                "f1-score": 0.9099339054947223,
                "support": 4945
            },
            "1": {
                "precision": 0.7479182437547313,
                "recall": 0.6301020408163265,
                "f1-score": 0.6839736933194878,
                "support": 1568
            },
            "accuracy": 0.8598188238906802,
            "macro avg": {
                "precision": 0.8181039600900004,
                "recall": 0.7813806462928953,
                "f1-score": 0.796953799407105,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8544953563842126,
                "recall": 0.8598188238906802,
                "f1-score": 0.8555341492087147,
                "support": 6513
            },
            "roc_auc": 0.9174497276160212,
            "score": 0.8598188238906802
        },
        "test": {
            "0": {
                "precision": 0.8892799755145765,
                "recall": 0.9346200241254523,
                "f1-score": 0.9113864491844417,
                "support": 12435
            },
            "1": {
                "precision": 0.7468866749688667,
                "recall": 0.623764950598024,
                "f1-score": 0.679795976197223,
                "support": 3846
            },
            "accuracy": 0.8611878877218844,
            "macro avg": {
                "precision": 0.8180833252417217,
                "recall": 0.7791924873617382,
                "f1-score": 0.7955912126908323,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8556429363954315,
                "recall": 0.8611878877218844,
                "f1-score": 0.8566786941872767,
                "support": 16281
            },
            "roc_auc": 0.9145696258087557,
            "score": 0.8611878877218844
        }
    }
}
