{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train1___c67f4f981d6c42ea917cf0801b8864c1.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7631631900194513,
                "recall": 0.7692515719018322,
                "f1-score": 0.7661952861952863,
                "support": 29582
            },
            "1": {
                "precision": 0.7927306956548144,
                "recall": 0.7870903554523803,
                "f1-score": 0.7899004568696862,
                "support": 33169
            },
            "accuracy": 0.7786808178355723,
            "macro avg": {
                "precision": 0.7779469428371328,
                "recall": 0.7781709636771063,
                "f1-score": 0.7780478715324863,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7787920181563631,
                "recall": 0.7786808178355723,
                "f1-score": 0.7787253941792097,
                "support": 62751
            },
            "roc_auc": 0.8623731664335246,
            "score": 0.7786808178355723
        },
        "val": {
            "0": {
                "precision": 0.7128480838158258,
                "recall": 0.6991617090319091,
                "f1-score": 0.705938566552901,
                "support": 7396
            },
            "1": {
                "precision": 0.7361868626986009,
                "recall": 0.7487940183309214,
                "f1-score": 0.742436924548607,
                "support": 8292
            },
            "accuracy": 0.725395206527282,
            "macro avg": {
                "precision": 0.7245174732572133,
                "recall": 0.7239778636814153,
                "f1-score": 0.7241877455507539,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7251839554690622,
                "recall": 0.725395206527282,
                "f1-score": 0.7252300240044816,
                "support": 15688
            },
            "roc_auc": 0.8050053848483829,
            "score": 0.725395206527282
        },
        "test": {
            "0": {
                "precision": 0.7048896581566422,
                "recall": 0.7048134126554895,
                "f1-score": 0.7048515333441506,
                "support": 9245
            },
            "1": {
                "precision": 0.7367354813814393,
                "recall": 0.7368065605402798,
                "f1-score": 0.736771019246539,
                "support": 10365
            },
            "accuracy": 0.7217236104028557,
            "macro avg": {
                "precision": 0.7208125697690407,
                "recall": 0.7208099865978846,
                "f1-score": 0.7208112762953448,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7217219864445066,
                "recall": 0.7217236104028557,
                "f1-score": 0.7217227965454894,
                "support": 19610
            },
            "roc_auc": 0.798988373788833,
            "score": 0.7217236104028557
        }
    }
}
