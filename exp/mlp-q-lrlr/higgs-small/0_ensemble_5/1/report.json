{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train1___adbb1ab716154c92a24aa521ae286bba.py",
    "data": "data/higgs-small",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.7576503930631938,
                "recall": 0.759110269758637,
                "f1-score": 0.7583796288478749,
                "support": 29582
            },
            "1": {
                "precision": 0.7847910123218169,
                "recall": 0.7834423708884802,
                "f1-score": 0.7841161117062205,
                "support": 33169
            },
            "accuracy": 0.7719717614061927,
            "macro avg": {
                "precision": 0.7712207026925053,
                "recall": 0.7712763203235586,
                "f1-score": 0.7712478702770478,
                "support": 62751
            },
            "weighted avg": {
                "precision": 0.7719964146435554,
                "recall": 0.7719717614061927,
                "f1-score": 0.7719834502997796,
                "support": 62751
            },
            "roc_auc": 0.8560018977189483,
            "score": 0.7719717614061927
        },
        "val": {
            "0": {
                "precision": 0.7236714975845411,
                "recall": 0.7088967009194159,
                "f1-score": 0.7162079092958131,
                "support": 7396
            },
            "1": {
                "precision": 0.7449958545540685,
                "recall": 0.7585624698504583,
                "f1-score": 0.7517179563788466,
                "support": 8292
            },
            "accuracy": 0.7351478837327894,
            "macro avg": {
                "precision": 0.7343336760693048,
                "recall": 0.733729585384937,
                "f1-score": 0.7339629328373298,
                "support": 15688
            },
            "weighted avg": {
                "precision": 0.7349426327191231,
                "recall": 0.7351478837327894,
                "f1-score": 0.7349769882359275,
                "support": 15688
            },
            "roc_auc": 0.8156404359457414,
            "score": 0.7351478837327894
        },
        "test": {
            "0": {
                "precision": 0.7117813588850174,
                "recall": 0.7070849107625744,
                "f1-score": 0.709425362200879,
                "support": 9245
            },
            "1": {
                "precision": 0.7402647228083638,
                "recall": 0.7446213217559093,
                "f1-score": 0.742436631234669,
                "support": 10365
            },
            "accuracy": 0.7269250382457929,
            "macro avg": {
                "precision": 0.7260230408466906,
                "recall": 0.7258531162592419,
                "f1-score": 0.7259309967177741,
                "support": 19610
            },
            "weighted avg": {
                "precision": 0.7268364362468474,
                "recall": 0.7269250382457929,
                "f1-score": 0.7268736948645829,
                "support": 19610
            },
            "roc_auc": 0.8072203094357205,
            "score": 0.7269250382457929
        }
    }
}
