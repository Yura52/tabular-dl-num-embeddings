{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train1___8b9b274bb0d74599927b8c80da4e0399.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8852606891574959,
                "recall": 0.9629120879120879,
                "f1-score": 0.9224551179622145,
                "support": 5096
            },
            "1": {
                "precision": 0.779463243873979,
                "recall": 0.5122699386503068,
                "f1-score": 0.6182322998611754,
                "support": 1304
            },
            "accuracy": 0.87109375,
            "macro avg": {
                "precision": 0.8323619665157375,
                "recall": 0.7375910132811974,
                "f1-score": 0.7703437089116949,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8637044596809794,
                "recall": 0.87109375,
                "f1-score": 0.8604697187741279,
                "support": 6400
            },
            "roc_auc": 0.88367064027121,
            "score": 0.87109375
        },
        "val": {
            "0": {
                "precision": 0.8810888252148997,
                "recall": 0.9654631083202512,
                "f1-score": 0.9213483146067416,
                "support": 1274
            },
            "1": {
                "precision": 0.7843137254901961,
                "recall": 0.49079754601226994,
                "f1-score": 0.6037735849056604,
                "support": 326
            },
            "accuracy": 0.86875,
            "macro avg": {
                "precision": 0.8327012753525479,
                "recall": 0.7281303271662606,
                "f1-score": 0.7625609497562009,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8613708986459914,
                "recall": 0.86875,
                "f1-score": 0.8566424634301464,
                "support": 1600
            },
            "roc_auc": 0.8737250917356087,
            "score": 0.86875
        },
        "test": {
            "0": {
                "precision": 0.8780767029192902,
                "recall": 0.9629629629629629,
                "f1-score": 0.9185628742514969,
                "support": 1593
            },
            "1": {
                "precision": 0.766798418972332,
                "recall": 0.47665847665847666,
                "f1-score": 0.5878787878787879,
                "support": 407
            },
            "accuracy": 0.864,
            "macro avg": {
                "precision": 0.8224375609458111,
                "recall": 0.7198107198107198,
                "f1-score": 0.7532208310651424,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8554315721360842,
                "recall": 0.864,
                "f1-score": 0.8512686626746506,
                "support": 2000
            },
            "roc_auc": 0.861524081863065,
            "score": 0.864
        }
    }
}
