{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train1___8b9b274bb0d74599927b8c80da4e0399.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8804075795495173,
                "recall": 0.9664442700156985,
                "f1-score": 0.9214218896164639,
                "support": 5096
            },
            "1": {
                "precision": 0.7878411910669976,
                "recall": 0.4869631901840491,
                "f1-score": 0.6018957345971564,
                "support": 1304
            },
            "accuracy": 0.86875,
            "macro avg": {
                "precision": 0.8341243853082574,
                "recall": 0.7267037300998738,
                "f1-score": 0.7616588121068102,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8615471778962038,
                "recall": 0.86875,
                "f1-score": 0.85631843553128,
                "support": 6400
            },
            "roc_auc": 0.8829189680827498,
            "score": 0.86875
        },
        "val": {
            "0": {
                "precision": 0.8800567778566359,
                "recall": 0.9733124018838305,
                "f1-score": 0.9243384271338055,
                "support": 1274
            },
            "1": {
                "precision": 0.8219895287958116,
                "recall": 0.4815950920245399,
                "f1-score": 0.6073500967117988,
                "support": 326
            },
            "accuracy": 0.873125,
            "macro avg": {
                "precision": 0.8510231533262238,
                "recall": 0.7274537469541852,
                "f1-score": 0.7658442619228022,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.868225575860493,
                "recall": 0.873125,
                "f1-score": 0.8597520548103216,
                "support": 1600
            },
            "roc_auc": 0.8705685199988442,
            "score": 0.873125
        },
        "test": {
            "0": {
                "precision": 0.8718238283455675,
                "recall": 0.9692404268675455,
                "f1-score": 0.9179548156956004,
                "support": 1593
            },
            "1": {
                "precision": 0.7860262008733624,
                "recall": 0.44226044226044225,
                "f1-score": 0.5660377358490566,
                "support": 407
            },
            "accuracy": 0.862,
            "macro avg": {
                "precision": 0.8289250146094649,
                "recall": 0.7057504345639939,
                "f1-score": 0.7419962757723285,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8543640111549737,
                "recall": 0.862,
                "f1-score": 0.8463396899468287,
                "support": 2000
            },
            "roc_auc": 0.861008928805539,
            "score": 0.862
        }
    }
}
