{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train1___2a2b817aa984482a8577f039de4825a3.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8929219600725953,
                "recall": 0.9654631083202512,
                "f1-score": 0.9277767301527436,
                "support": 5096
            },
            "1": {
                "precision": 0.802247191011236,
                "recall": 0.5475460122699386,
                "f1-score": 0.6508659981768459,
                "support": 1304
            },
            "accuracy": 0.8803125,
            "macro avg": {
                "precision": 0.8475845755419156,
                "recall": 0.7565045602950948,
                "f1-score": 0.7893213641647947,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8744469758763433,
                "recall": 0.8803125,
                "f1-score": 0.8713561685126544,
                "support": 6400
            },
            "roc_auc": 0.9081116489776655,
            "score": 0.8803125
        },
        "val": {
            "0": {
                "precision": 0.8851399856424982,
                "recall": 0.9678178963893249,
                "f1-score": 0.9246344206974129,
                "support": 1274
            },
            "1": {
                "precision": 0.8019323671497585,
                "recall": 0.50920245398773,
                "f1-score": 0.6228893058161351,
                "support": 326
            },
            "accuracy": 0.874375,
            "macro avg": {
                "precision": 0.8435361763961283,
                "recall": 0.7385101751885275,
                "f1-score": 0.773761863256774,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8681864333746024,
                "recall": 0.874375,
                "f1-score": 0.8631538535403525,
                "support": 1600
            },
            "roc_auc": 0.8628901773073553,
            "score": 0.874375
        },
        "test": {
            "0": {
                "precision": 0.8767990788716177,
                "recall": 0.9560577526679221,
                "f1-score": 0.9147147147147147,
                "support": 1593
            },
            "1": {
                "precision": 0.7338403041825095,
                "recall": 0.4742014742014742,
                "f1-score": 0.5761194029850746,
                "support": 407
            },
            "accuracy": 0.858,
            "macro avg": {
                "precision": 0.8053196915270635,
                "recall": 0.7151296134346982,
                "f1-score": 0.7454170588498946,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8477069682223841,
                "recall": 0.858,
                "f1-score": 0.8458105687777329,
                "support": 2000
            },
            "roc_auc": 0.85473300727538,
            "score": 0.858
        }
    }
}
