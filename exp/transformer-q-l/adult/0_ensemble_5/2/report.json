{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train1___47a46a8537f744f38092988671288900.py",
    "data": "data/adult",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9068741516385496,
                "recall": 0.9459924146649811,
                "f1-score": 0.9260203450238844,
                "support": 19775
            },
            "1": {
                "precision": 0.8029520295202952,
                "recall": 0.6937669376693767,
                "f1-score": 0.7443769776789532,
                "support": 6273
            },
            "accuracy": 0.8852503071253072,
            "macro avg": {
                "precision": 0.8549130905794224,
                "recall": 0.8198796761671789,
                "f1-score": 0.8351986613514188,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8818471448799573,
                "recall": 0.8852503071253072,
                "f1-score": 0.8822761480277713,
                "support": 26048
            },
            "roc_auc": 0.9420011354423056,
            "score": 0.8852503071253072
        },
        "val": {
            "0": {
                "precision": 0.8960788101216921,
                "recall": 0.9381193124368049,
                "f1-score": 0.9166172693143648,
                "support": 4945
            },
            "1": {
                "precision": 0.7709580838323353,
                "recall": 0.6568877551020408,
                "f1-score": 0.7093663911845729,
                "support": 1568
            },
            "accuracy": 0.8704130201136189,
            "macro avg": {
                "precision": 0.8335184469770137,
                "recall": 0.7975035337694228,
                "f1-score": 0.8129918302494689,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8659560865194026,
                "recall": 0.8704130201136189,
                "f1-score": 0.8667217715548818,
                "support": 6513
            },
            "roc_auc": 0.9275231629557789,
            "score": 0.8704130201136189
        },
        "test": {
            "0": {
                "precision": 0.8974932510605477,
                "recall": 0.9357458785685565,
                "f1-score": 0.9162204724409448,
                "support": 12435
            },
            "1": {
                "precision": 0.7590470446320868,
                "recall": 0.6544461778471139,
                "f1-score": 0.7028762915386764,
                "support": 3846
            },
            "accuracy": 0.8692954978195443,
            "macro avg": {
                "precision": 0.8282701478463173,
                "recall": 0.7950960282078352,
                "f1-score": 0.8095483819898106,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.8647886192858496,
                "recall": 0.8692954978195443,
                "f1-score": 0.8658229710743135,
                "support": 16281
            },
            "roc_auc": 0.921842515035543,
            "score": 0.8692954978195443
        }
    }
}
