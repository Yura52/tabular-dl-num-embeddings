{
    "program": "bin/train3___9fc194f1e4dc41ac89a16e7cb80c53bc.py",
    "environment": {
        "CUDA_VISIBLE_DEVICES": "0",
        "gpus": {
            "driver": "460.106.00",
            "devices": [
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11554717696,
                    "memory_free": 11550654464,
                    "memory_used": 4063232,
                    "utilization": 0
                },
                {
                    "name": "GeForce RTX 2080 Ti",
                    "memory_total": 11552096256,
                    "memory_free": 2789277696,
                    "memory_used": 8762818560,
                    "utilization": 52
                }
            ]
        },
        "torch.version.cuda": "11.1",
        "torch.backends.cudnn.version()": 8005,
        "torch.cuda.nccl.version()": [
            2,
            10,
            3
        ]
    },
    "config": {
        "seed": 8,
        "data": {
            "path": "data/eye",
            "T": {
                "seed": 0,
                "normalization": "standard",
                "num_nan_policy": null,
                "cat_nan_policy": null,
                "cat_min_frequency": null,
                "cat_encoding": null,
                "y_policy": "default"
            },
            "T_cache": true
        },
        "model": {
            "d_num_embedding": 106,
            "num_embedding_arch": [
                "positional",
                "linear",
                "relu",
                "linear",
                "relu"
            ],
            "d_cat_embedding": null,
            "mlp": {
                "d_layers": [
                    766
                ],
                "dropout": 0.06445379195581596
            },
            "resnet": null,
            "transformer": null,
            "transformer_default": false,
            "transformer_baseline": true,
            "periodic_sigma": null,
            "positional_encoding": {
                "n": 123,
                "sigma": 19.178816383731053,
                "trainable": true,
                "initialization": "normal"
            },
            "fourier_features": null,
            "memory_efficient": false
        },
        "training": {
            "batch_size": 128,
            "lr": 0.003844982988384105,
            "weight_decay": 0.0,
            "optimizer": "AdamW",
            "patience": 16,
            "n_epochs": Infinity,
            "eval_batch_size": 8192
        },
        "bins": null
    },
    "prediction_type": "logits",
    "epoch_size": 55,
    "n_parameters": 3092985,
    "best_epoch": 51,
    "metrics": {
        "train": {
            "0": {
                "precision": 0.997949979499795,
                "recall": 1.0,
                "f1-score": 0.9989739380258568,
                "support": 2434
            },
            "1": {
                "precision": 1.0,
                "recall": 0.9988998899889989,
                "f1-score": 0.9994496422674739,
                "support": 2727
            },
            "2": {
                "precision": 1.0,
                "recall": 0.9989112683723462,
                "f1-score": 0.9994553376906318,
                "support": 1837
            },
            "accuracy": 0.999285510145756,
            "macro avg": {
                "precision": 0.9993166598332651,
                "recall": 0.9992703861204483,
                "f1-score": 0.9992929726613208,
                "support": 6998
            },
            "weighted avg": {
                "precision": 0.9992869748646044,
                "recall": 0.999285510145756,
                "f1-score": 0.9992856809025474,
                "support": 6998
            },
            "score": 0.999285510145756
        },
        "val": {
            "0": {
                "precision": 0.9966777408637874,
                "recall": 0.9852216748768473,
                "f1-score": 0.990916597853014,
                "support": 609
            },
            "1": {
                "precision": 0.9883381924198251,
                "recall": 0.9941348973607038,
                "f1-score": 0.9912280701754387,
                "support": 682
            },
            "2": {
                "precision": 0.9913419913419913,
                "recall": 0.9978213507625272,
                "f1-score": 0.99457111834962,
                "support": 459
            },
            "accuracy": 0.992,
            "macro avg": {
                "precision": 0.9921193082085346,
                "recall": 0.9923926410000261,
                "f1-score": 0.9922385954593574,
                "support": 1750
            },
            "weighted avg": {
                "precision": 0.992028208824195,
                "recall": 0.992,
                "f1-score": 0.9919965115854915,
                "support": 1750
            },
            "score": 0.992
        },
        "test": {
            "0": {
                "precision": 0.986737400530504,
                "recall": 0.9776609724047306,
                "f1-score": 0.9821782178217822,
                "support": 761
            },
            "1": {
                "precision": 0.9859649122807017,
                "recall": 0.9882766705744431,
                "f1-score": 0.9871194379391101,
                "support": 853
            },
            "2": {
                "precision": 0.9896373056994818,
                "recall": 0.9982578397212544,
                "f1-score": 0.9939288811795316,
                "support": 574
            },
            "accuracy": 0.9872029250457038,
            "macro avg": {
                "precision": 0.9874465395035625,
                "recall": 0.9880651609001427,
                "f1-score": 0.9877421789801413,
                "support": 2188
            },
            "weighted avg": {
                "precision": 0.9871970043193119,
                "recall": 0.9872029250457038,
                "f1-score": 0.9871872404577187,
                "support": 2188
            },
            "score": 0.9872029250457038
        }
    },
    "eval_batch_size": 2048,
    "time": "0:00:41"
}
