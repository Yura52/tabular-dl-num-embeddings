{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            0,
            1,
            2,
            3,
            4
        ]
    },
    "single_model_program": "bin/train3___fab6e55a06624cecb76cd4e5d96fe1e7.py",
    "data": "data/covtype",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.9933018095441837,
                "recall": 0.9931626075026921,
                "f1-score": 0.9932322036461271,
                "support": 135578
            },
            "1": {
                "precision": 0.996758068806526,
                "recall": 0.9920082509707024,
                "f1-score": 0.9943774878372402,
                "support": 181312
            },
            "2": {
                "precision": 0.9934247768343131,
                "recall": 0.9970282317979198,
                "f1-score": 0.9952232425240475,
                "support": 22882
            },
            "3": {
                "precision": 0.9781390134529148,
                "recall": 0.992040932347925,
                "f1-score": 0.9850409257691223,
                "support": 1759
            },
            "4": {
                "precision": 0.9428437938015886,
                "recall": 0.9965432098765432,
                "f1-score": 0.9689500640204866,
                "support": 6075
            },
            "5": {
                "precision": 0.9881239396374676,
                "recall": 0.995591542959964,
                "f1-score": 0.9918436855785606,
                "support": 11115
            },
            "6": {
                "precision": 0.9737213272956722,
                "recall": 0.9993143379552034,
                "f1-score": 0.9863518441929542,
                "support": 13126
            },
            "accuracy": 0.9931773014169807,
            "macro avg": {
                "precision": 0.9809018184818095,
                "recall": 0.9950984447729929,
                "f1-score": 0.9878599219383626,
                "support": 371847
            },
            "weighted avg": {
                "precision": 0.9932526112958144,
                "recall": 0.9931773014169807,
                "f1-score": 0.9931933309010167,
                "support": 371847
            },
            "score": 0.9931773014169807
        },
        "val": {
            "0": {
                "precision": 0.974417987076215,
                "recall": 0.9743317401309967,
                "f1-score": 0.9743748616950653,
                "support": 33894
            },
            "1": {
                "precision": 0.9826596028848722,
                "recall": 0.9739013413342746,
                "f1-score": 0.9782608695652174,
                "support": 45328
            },
            "2": {
                "precision": 0.9660578911095796,
                "recall": 0.9800734137388568,
                "f1-score": 0.9730151843817786,
                "support": 5721
            },
            "3": {
                "precision": 0.9214780600461894,
                "recall": 0.908883826879271,
                "f1-score": 0.915137614678899,
                "support": 439
            },
            "4": {
                "precision": 0.8637454981992797,
                "recall": 0.9473337722185649,
                "f1-score": 0.9036106750392465,
                "support": 1519
            },
            "5": {
                "precision": 0.9438559322033898,
                "recall": 0.9618567830154732,
                "f1-score": 0.9527713420067724,
                "support": 2779
            },
            "6": {
                "precision": 0.9466588511137163,
                "recall": 0.9841560024375381,
                "f1-score": 0.9650433223782492,
                "support": 3282
            },
            "accuracy": 0.9736989307458962,
            "macro avg": {
                "precision": 0.9426962603761775,
                "recall": 0.9615052685364249,
                "f1-score": 0.9517448385350326,
                "support": 92962
            },
            "weighted avg": {
                "precision": 0.9739700436053228,
                "recall": 0.9736989307458962,
                "f1-score": 0.9737747025613022,
                "support": 92962
            },
            "score": 0.9736989307458962
        },
        "test": {
            "0": {
                "precision": 0.9736929107826005,
                "recall": 0.9731873111782477,
                "f1-score": 0.9734400453289893,
                "support": 42368
            },
            "1": {
                "precision": 0.981632435126188,
                "recall": 0.9734032226752087,
                "f1-score": 0.977500509539465,
                "support": 56661
            },
            "2": {
                "precision": 0.9631057268722467,
                "recall": 0.9783247098307929,
                "f1-score": 0.9706555671175859,
                "support": 7151
            },
            "3": {
                "precision": 0.915129151291513,
                "recall": 0.9034608378870674,
                "f1-score": 0.9092575618698443,
                "support": 549
            },
            "4": {
                "precision": 0.8715953307392996,
                "recall": 0.9436545550289626,
                "f1-score": 0.9061946902654867,
                "support": 1899
            },
            "5": {
                "precision": 0.9429948950652297,
                "recall": 0.9573855456377771,
                "f1-score": 0.9501357336762396,
                "support": 3473
            },
            "6": {
                "precision": 0.9455988792902171,
                "recall": 0.9873232569478303,
                "f1-score": 0.9660107334525938,
                "support": 4102
            },
            "accuracy": 0.9728234210820719,
            "macro avg": {
                "precision": 0.941964189881042,
                "recall": 0.9595342055979839,
                "f1-score": 0.9504564058928864,
                "support": 116203
            },
            "weighted avg": {
                "precision": 0.9730583462916497,
                "recall": 0.9728234210820719,
                "f1-score": 0.9728876683212389,
                "support": 116203
            },
            "score": 0.9728234210820719
        }
    }
}
