{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train3___9bbd70646e104cb3b127ca37b8319cab.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8786303334528505,
                "recall": 0.9617346938775511,
                "f1-score": 0.9183061645118982,
                "support": 5096
            },
            "1": {
                "precision": 0.7627737226277372,
                "recall": 0.4808282208588957,
                "f1-score": 0.5898400752587017,
                "support": 1304
            },
            "accuracy": 0.86375,
            "macro avg": {
                "precision": 0.8207020280402939,
                "recall": 0.7212814573682234,
                "f1-score": 0.7540731198852999,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8550245489972336,
                "recall": 0.86375,
                "f1-score": 0.8513811988265593,
                "support": 6400
            },
            "roc_auc": 0.878639477853435,
            "score": 0.86375
        },
        "val": {
            "0": {
                "precision": 0.8823109843081313,
                "recall": 0.9709576138147566,
                "f1-score": 0.9245142002989536,
                "support": 1274
            },
            "1": {
                "precision": 0.8131313131313131,
                "recall": 0.4938650306748466,
                "f1-score": 0.6145038167938931,
                "support": 326
            },
            "accuracy": 0.87375,
            "macro avg": {
                "precision": 0.8477211487197223,
                "recall": 0.7324113222448017,
                "f1-score": 0.7695090085464233,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8682156263058546,
                "recall": 0.87375,
                "f1-score": 0.8613495846597975,
                "support": 1600
            },
            "roc_auc": 0.8623749169323226,
            "score": 0.87375
        },
        "test": {
            "0": {
                "precision": 0.8735763097949886,
                "recall": 0.9629629629629629,
                "f1-score": 0.9160943565243356,
                "support": 1593
            },
            "1": {
                "precision": 0.7581967213114754,
                "recall": 0.45454545454545453,
                "f1-score": 0.5683563748079877,
                "support": 407
            },
            "accuracy": 0.8595,
            "macro avg": {
                "precision": 0.815886515553232,
                "recall": 0.7087542087542087,
                "f1-score": 0.7422253656661617,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8500965635385938,
                "recall": 0.8595,
                "f1-score": 0.8453296772450587,
                "support": 2000
            },
            "roc_auc": 0.8518688179705127,
            "score": 0.8595
        }
    }
}
