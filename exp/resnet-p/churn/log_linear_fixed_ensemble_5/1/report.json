{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            5,
            6,
            7,
            8,
            9
        ]
    },
    "single_model_program": "bin/train3___2e8d5030eaeb493ab5c3c493c6dd49db.py",
    "data": "data/churn",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.872634898388227,
                "recall": 0.9774332810047096,
                "f1-score": 0.9220659015179562,
                "support": 5096
            },
            "1": {
                "precision": 0.8338150289017341,
                "recall": 0.4424846625766871,
                "f1-score": 0.5781563126252505,
                "support": 1304
            },
            "accuracy": 0.8684375,
            "macro avg": {
                "precision": 0.8532249636449806,
                "recall": 0.7099589717906983,
                "f1-score": 0.7501111070716033,
                "support": 6400
            },
            "weighted avg": {
                "precision": 0.8647253499803541,
                "recall": 0.8684375,
                "f1-score": 0.8519943227810675,
                "support": 6400
            },
            "roc_auc": 0.8948545292350069,
            "score": 0.8684375
        },
        "val": {
            "0": {
                "precision": 0.8678720445062587,
                "recall": 0.9795918367346939,
                "f1-score": 0.9203539823008849,
                "support": 1274
            },
            "1": {
                "precision": 0.8395061728395061,
                "recall": 0.4171779141104294,
                "f1-score": 0.5573770491803278,
                "support": 326
            },
            "accuracy": 0.865,
            "macro avg": {
                "precision": 0.8536891086728824,
                "recall": 0.6983848754225617,
                "f1-score": 0.7388655157406063,
                "support": 1600
            },
            "weighted avg": {
                "precision": 0.8620924981541579,
                "recall": 0.865,
                "f1-score": 0.8463974321775715,
                "support": 1600
            },
            "roc_auc": 0.8508610145332319,
            "score": 0.865
        },
        "test": {
            "0": {
                "precision": 0.8634092171016102,
                "recall": 0.9761456371625863,
                "f1-score": 0.91632292280495,
                "support": 1593
            },
            "1": {
                "precision": 0.8090452261306532,
                "recall": 0.3955773955773956,
                "f1-score": 0.5313531353135315,
                "support": 407
            },
            "accuracy": 0.858,
            "macro avg": {
                "precision": 0.8362272216161317,
                "recall": 0.6858615163699909,
                "f1-score": 0.7238380290592408,
                "support": 2000
            },
            "weighted avg": {
                "precision": 0.8523461449390204,
                "recall": 0.858,
                "f1-score": 0.8379815710504462,
                "support": 2000
            },
            "roc_auc": 0.8460201341557274,
            "score": 0.858
        }
    }
}
