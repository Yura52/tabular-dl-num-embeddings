{
    "program": "bin/ensemble.py",
    "config": {
        "seeds": [
            10,
            11,
            12,
            13,
            14
        ]
    },
    "single_model_program": "bin/train3___5918847956594863aa2e1b1b50061104.py",
    "data": "data/adult",
    "prediction_type": "probs",
    "metrics": {
        "train": {
            "0": {
                "precision": 0.8978961865412927,
                "recall": 0.9561061946902655,
                "f1-score": 0.926087382445141,
                "support": 19775
            },
            "1": {
                "precision": 0.8260869565217391,
                "recall": 0.6572612784951379,
                "f1-score": 0.7320667613636365,
                "support": 6273
            },
            "accuracy": 0.8841369778869779,
            "macro avg": {
                "precision": 0.8619915715315158,
                "recall": 0.8066837365927018,
                "f1-score": 0.8290770719043887,
                "support": 26048
            },
            "weighted avg": {
                "precision": 0.8806027551871517,
                "recall": 0.8841369778869779,
                "f1-score": 0.879362437879559,
                "support": 26048
            },
            "roc_auc": 0.9483811240878824,
            "score": 0.8841369778869779
        },
        "val": {
            "0": {
                "precision": 0.8877299450028446,
                "recall": 0.9466127401415572,
                "f1-score": 0.9162262673713055,
                "support": 4945
            },
            "1": {
                "precision": 0.7870967741935484,
                "recall": 0.6224489795918368,
                "f1-score": 0.6951566951566951,
                "support": 1568
            },
            "accuracy": 0.8685705512052817,
            "macro avg": {
                "precision": 0.8374133595981965,
                "recall": 0.7845308598666969,
                "f1-score": 0.8056914812640004,
                "support": 6513
            },
            "weighted avg": {
                "precision": 0.8635025825233458,
                "recall": 0.8685705512052817,
                "f1-score": 0.8630039290890225,
                "support": 6513
            },
            "roc_auc": 0.9286081849322135,
            "score": 0.8685705512052817
        },
        "test": {
            "0": {
                "precision": 0.8923030348898812,
                "recall": 0.9481302774427021,
                "f1-score": 0.919369931378665,
                "support": 12435
            },
            "1": {
                "precision": 0.7897653194263363,
                "recall": 0.6300052002080083,
                "f1-score": 0.7008967312698872,
                "support": 3846
            },
            "accuracy": 0.8729807751366624,
            "macro avg": {
                "precision": 0.8410341771581087,
                "recall": 0.7890677388253552,
                "f1-score": 0.810133331324276,
                "support": 16281
            },
            "weighted avg": {
                "precision": 0.868080932213584,
                "recall": 0.8729807751366624,
                "f1-score": 0.8677608209052076,
                "support": 16281
            },
            "roc_auc": 0.9251843230142556,
            "score": 0.8729807751366624
        }
    }
}
